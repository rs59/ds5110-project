{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File 01 - Preprocessed Data Output (Step 1)\n",
    "##### Group 12:\n",
    "\n",
    "##### Hannah Schmuckler, mmc4cv\n",
    "\n",
    "##### Rob Schwartz, res7cd\n",
    "\n",
    "In this file, we create the scaffolding of the preprocessed user-level data from event-level data, with a few features. The event-level data is given with 1 record equal to one interaction, while the user-level data is given with 1 record equal to one user. Each row in the output data represents one user who exists in the first month.\n",
    "\n",
    "Outputs:\n",
    "- The preprocessed data file is output to `processed_data/preprocessed_01.parquet`.\n",
    "- Additionally, the raw data is filtered on the preprocessed data user ids: `processed_data/month_01_filtered.parquet`, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up Spark session and data schema\n",
    "\n",
    "We can specify more options in the SparkSession creator, but currently the options are at the default settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 163 ms, sys: 126 ms, total: 289 ms\n",
      "Wall time: 4.21 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import types as T\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "        .appName(\"project\") \\\n",
    "        .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext\n",
    "\n",
    "schema = \"`event_time` TIMESTAMP,`event_type` STRING,`product_id` INT,`category_id` BIGINT,`category_code` STRING,`brand` STRING,`price` FLOAT,`user_id` INT,`user_session` STRING\"\n",
    "#ddl_schema = T._parse_datatype_string(schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.32 ms, sys: 1.17 ms, total: 3.49 ms\n",
      "Wall time: 1.38 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Be sure that you have downloaded the data from either\n",
    "# - https://www.kaggle.com/datasets/mkechinov/ecommerce-behavior-data-from-multi-category-store\n",
    "# - https://drive.google.com/drive/folders/1Nan8X33H8xrXS5XhCKZmSpClFTCJsSpE\n",
    "# Then we are using January and Febrary 2020.\n",
    "\n",
    "df1 = spark.read.schema(schema).csv(\"/project/ds5559/group12/raw_data/2020-01.csv\")\n",
    "df2 = spark.read.schema(schema).csv(\"/project/ds5559/group12/raw_data/2020-02.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create temp views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Spark SQL\n",
    "df1.createOrReplaceTempView(\"m1\")\n",
    "df2.createOrReplaceTempView(\"m2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a transformed table containing elements of interest for our model\n",
    "\n",
    "We propose a basic table format (see https://docs.google.com/document/d/1NG4KGticBXn0D3PL5_zMxLV2Pr7A8PQtLcasxCOd1nA/edit).\n",
    "\n",
    "Every row is a user_id who exists in M1 and may or may not exist in M2.\n",
    "Columns include:\n",
    "- `user_id` (ID)\n",
    "- `total_spend` (sum among all purchase events in month 1)\n",
    "- `total_events` (count of distinct user actions during month 1)\n",
    "- `user_sessions` (count of distinct user sessions/browsing sessions during month 1)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------------+------------+--------------+\n",
      "|  user_id|      total_spend|total_events|total_sessions|\n",
      "+---------+-----------------+------------+--------------+\n",
      "|597644399|              0.0|       41280|         40188|\n",
      "|569335945|              0.0|       23058|         23057|\n",
      "|594718064|              0.0|       16347|         15890|\n",
      "|597514055|              0.0|       13717|         12952|\n",
      "|568804062|172.9600067138672|       11479|          9149|\n",
      "+---------+-----------------+------------+--------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "CPU times: user 4.23 ms, sys: 4.66 ms, total: 8.89 ms\n",
      "Wall time: 51.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = spark.sql(\"\"\"SELECT\n",
    "\n",
    "               /* ID */\n",
    "               m1.user_id AS user_id,\n",
    "               \n",
    "               /* Total spend in month 1: we sum the price of any 'purchase' events */\n",
    "               SUM(CAST(m1.event_type=='purchase' AS INT) * m1.price) AS total_spend,\n",
    "               \n",
    "               /* Total events in month 1: includes all event types (multiple per session) */\n",
    "               COUNT(m1.event_type) AS total_events,\n",
    "               \n",
    "               /* Total user sessions in month 1: we count all distinct user sessions */\n",
    "               COUNT(DISTINCT m1.user_session) AS total_sessions\n",
    "               \n",
    "               FROM m1\n",
    "               \n",
    "            /* Note: This is a left join, so purchasers in month 2 must be in month 1 to be included in the output */\n",
    "            LEFT JOIN\n",
    "            (\n",
    "               SELECT\n",
    "                 user_id,\n",
    "                 SUM(m2.price) AS price FROM m2\n",
    "                 \n",
    "               WHERE event_type='purchase'\n",
    "               GROUP BY m2.user_id\n",
    "            ) m2\n",
    "           \n",
    "            ON m1.user_id=m2.user_id\n",
    "           \n",
    "            /* Prevent adding bad data where user_id is null */\n",
    "            WHERE ISNULL(m1.user_id)<>1\n",
    "\n",
    "            GROUP BY m1.user_id ORDER BY total_events DESC\n",
    "           \n",
    "            \"\"\")\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove customers who did not make a purchase in month 1.\n",
    "We do this because it is unlikely that we"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.filter(col('total_spend') > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "359105"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create response variable (individual level) of total spend in month 2 (T_total_spend), join with month 1 data, and fill nulls with 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_spend_response = df2.filter(col('event_type') == \"purchase\").groupBy(col('user_id')).sum('price').withColumnRenamed('sum(price)', \"T_total_spend\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------------+------------+--------------+------------------+\n",
      "|  user_id|       total_spend|total_events|total_sessions|     T_total_spend|\n",
      "+---------+------------------+------------+--------------+------------------+\n",
      "|512372691|146.91000366210938|          33|             3| 429.9599914550781|\n",
      "|512407417| 805.9299926757812|          42|            11|              null|\n",
      "|512423995|129.99000549316406|          88|            11|              null|\n",
      "|512428523| 5860.260070800781|          34|             7|              null|\n",
      "|512445637|27.799999237060547|          50|             7|              null|\n",
      "|512448189| 267.2900085449219|           9|             1|328.29998779296875|\n",
      "|512460113|  96.5199966430664|          13|             4| 133.2599983215332|\n",
      "|512479812|166.19000244140625|          73|             9|  697.010009765625|\n",
      "|512510580|28.829999923706055|          78|            19|             262.5|\n",
      "|512513760| 94.47000122070312|         160|            41| 401.0400085449219|\n",
      "|512517137|243.72999572753906|          13|             3|              null|\n",
      "|512541716| 250.7100067138672|          53|            16|              null|\n",
      "|512547480| 336.5299987792969|          37|             6|              null|\n",
      "|512550513|171.69000244140625|         223|            47|22.200000762939453|\n",
      "|512552482|  62.5099983215332|          85|            14|              null|\n",
      "|512555062| 865.9000244140625|          30|             7|              null|\n",
      "|512562561| 38.33000183105469|          82|            11|              null|\n",
      "|512562754| 40.93000030517578|         322|            38|              null|\n",
      "|512583155|443.65999603271484|          22|             4|131.27999877929688|\n",
      "|512596570| 859.5499877929688|         143|            21|              null|\n",
      "+---------+------------------+------------+--------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "CPU times: user 8.54 ms, sys: 5.75 ms, total: 14.3 ms\n",
      "Wall time: 1min 8s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "359105"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "df = df.join(total_spend_response, df.user_id == total_spend_response.user_id, 'leftouter').drop(total_spend_response.user_id)\n",
    "\n",
    "#df.show()\n",
    "#df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------------+------------+--------------+------------------+\n",
      "|  user_id|       total_spend|total_events|total_sessions|     T_total_spend|\n",
      "+---------+------------------+------------+--------------+------------------+\n",
      "|512372691|146.91000366210938|          33|             3| 429.9599914550781|\n",
      "|512407417| 805.9299926757812|          42|            11|               0.0|\n",
      "|512423995|129.99000549316406|          88|            11|               0.0|\n",
      "|512428523| 5860.260070800781|          34|             7|               0.0|\n",
      "|512445637|27.799999237060547|          50|             7|               0.0|\n",
      "|512448189| 267.2900085449219|           9|             1|328.29998779296875|\n",
      "|512460113|  96.5199966430664|          13|             4| 133.2599983215332|\n",
      "|512479812|166.19000244140625|          73|             9|  697.010009765625|\n",
      "|512510580|28.829999923706055|          78|            19|             262.5|\n",
      "|512513760| 94.47000122070312|         160|            41| 401.0400085449219|\n",
      "|512517137|243.72999572753906|          13|             3|               0.0|\n",
      "|512541716| 250.7100067138672|          53|            16|               0.0|\n",
      "|512547480| 336.5299987792969|          37|             6|               0.0|\n",
      "|512550513|171.69000244140625|         223|            47|22.200000762939453|\n",
      "|512552482|  62.5099983215332|          85|            14|               0.0|\n",
      "|512555062| 865.9000244140625|          30|             7|               0.0|\n",
      "|512562561| 38.33000183105469|          82|            11|               0.0|\n",
      "|512562754| 40.93000030517578|         322|            38|               0.0|\n",
      "|512583155|443.65999603271484|          22|             4|131.27999877929688|\n",
      "|512596570| 859.5499877929688|         143|            21|               0.0|\n",
      "+---------+------------------+------------+--------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.fillna(0.0, \"T_total_spend\")\n",
    "#df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.write.mode(\"overwrite\").parquet(\"./processed_data/preprocessed_01.parquet\")\n",
    "#print(df.count())\n",
    "#df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write to CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1 µs, sys: 2 µs, total: 3 µs\n",
      "Wall time: 5.96 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Not necessary at this time, but this CSV can be written if desired\n",
    "# kept_df.coalesce(1).write.option(\"header\", \"true\").csv(\"./processed_data/temp_preprocessed_01.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write the raw data, filtered on the appropriate user-ids, to files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 615 µs, sys: 729 µs, total: 1.34 ms\n",
      "Wall time: 11 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# month_01_filtered = df1.join(kept_df,'user_id','leftsemi')\n",
    "month_01_filtered = df1.join(df,'user_id','leftsemi')\n",
    "#print(month_01_filtered.count())\n",
    "#month_01_filtered.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15923973"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "month_01_filtered.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.1 ms, sys: 12.4 ms, total: 24.5 ms\n",
      "Wall time: 2min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "month_01_filtered.write.mode(\"overwrite\").parquet(\"./processed_data/month_01_filtered.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DS 5110 Spark 3.1",
   "language": "python",
   "name": "ds5110_spark3.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
