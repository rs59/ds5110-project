{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File 05 - Basic Regression\n",
    "\n",
    "In this file, we create a small ML pipeline based on the output from File 03 (Basic Preprocessed Output).\n",
    "The files needed are `/processed_data/train_output.parquet` and `/processed_data/test_output.parquet`.\n",
    "\n",
    "The goal of this file is to provide:\n",
    "- The type of model (e.g., logistic regression)\n",
    "- Best hyperparameters used\n",
    "- Size of the saved model\n",
    "- Performance metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up Spark session\n",
    "\n",
    "We can specify more options in the SparkSession creator, but currently the options are at the default settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 371 ms, sys: 321 ms, total: 692 ms\n",
      "Wall time: 4.38 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import types as T\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.functions import log\n",
    "\n",
    "import pandas as pd\n",
    "import copy\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "        .appName(\"project\") \\\n",
    "        .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in dataframes for train and test sets\n",
    "\n",
    "This data should have been previously generated: we can find it in the `processed_data` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------+--------------+---------------+------------------+----------------+\n",
      "| user_id|m2_total_spend|m1_total_spend|m1_total_events|m1_purchase_events|m1_user_sessions|\n",
      "+--------+--------------+--------------+---------------+------------------+----------------+\n",
      "|22165363|          0.00|          0.00|              2|                 0|               2|\n",
      "|32978429|          0.00|          0.00|              8|                 0|               2|\n",
      "|38661019|          0.00|          0.00|              1|                 0|               1|\n",
      "|49484535|          0.00|          0.00|             22|                 0|              18|\n",
      "|62336140|          0.00|          0.00|              1|                 0|               1|\n",
      "+--------+--------------+--------------+---------------+------------------+----------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "CPU times: user 2.53 ms, sys: 345 Âµs, total: 2.88 ms\n",
      "Wall time: 3.09 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "trainDF = spark.read.parquet(\"./processed_data/train_output.parquet\")\n",
    "testDF = spark.read.parquet(\"./processed_data/test_output.parquet\")\n",
    "trainDF.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up Spark ML pipeline training for linear regression\n",
    "\n",
    "Here we decide which input columns should be used in order to create our training pipeline. To implement this step, we create the function `generateLRModel(inputCols, outputCol, trainDF)`. Then, we train the pipeline using this function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.21 ms, sys: 3.4 ms, total: 11.6 ms\n",
      "Wall time: 11.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "inputCols = [\"m1_total_spend\",\"m1_total_events\",\"m1_purchase_events\",\"m1_user_sessions\"]\n",
    "\n",
    "def generateLRModel(inputCols, outputCol, trainDF):\n",
    "    # Select input columns for linear regression\n",
    "    vecAssembler = VectorAssembler(inputCols=inputCols, outputCol=\"features\")\n",
    "\n",
    "    # Select output column for linear regression\n",
    "    lr = LinearRegression(featuresCol=\"features\", labelCol=outputCol)\n",
    "\n",
    "    # The following lines (pipeline creation and fitting) replace these two commented-out lines.\n",
    "    # vecTrainDF = vecAssembler.transform(trainDF)\n",
    "    # lrModel = lr.fit(vecTrainDF)\n",
    "    pipeline = Pipeline(stages=[vecAssembler, lr])\n",
    "    pipelineModel = pipeline.fit(trainDF)\n",
    "    return pipelineModel\n",
    "    \n",
    "pipelineModel = generateLRModel(inputCols, \"m2_total_spend\", trainDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View the model information\n",
    "\n",
    "Print out the model coefficients and view the RMSE and R^2. We define the functions `modelInfo(inputCols, pipelineModel)` and `getEvaluationMetrics(pipelineModel,outputCol,testDF)` to report this information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model coefficients\n",
      "          Column name  Coefficient\n",
      "0           intercept -2041.194264\n",
      "1      m1_total_spend     5.120766\n",
      "2     m1_total_events   274.648877\n",
      "3  m1_purchase_events -1424.596141\n",
      "4    m1_user_sessions  -297.351526\n"
     ]
    }
   ],
   "source": [
    "def modelInfo(inputCols, pipelineModel):\n",
    "    # Create a zipped list containing the coefficients and the data\n",
    "    modelCols = copy.deepcopy(inputCols)\n",
    "    modelCoeffs = list(pipelineModel.stages[-1].coefficients)\n",
    "    modelCoeffs.insert(0,pipelineModel.stages[-1].intercept)\n",
    "    modelCols.insert(0,\"intercept\")\n",
    "    modelZippedList = list(map(list, zip(modelCols, modelCoeffs)))\n",
    "\n",
    "    # Create the pandas DataFrame\n",
    "    modelDF = pd.DataFrame(modelZippedList, columns = ['Column name', 'Coefficient'])\n",
    "    return modelDF\n",
    "\n",
    "print(\"Model coefficients\")\n",
    "print(modelInfo(inputCols, pipelineModel))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-------------------+\n",
      "|m2_total_spend|         prediction|\n",
      "+--------------+-------------------+\n",
      "|          0.00|-2063.8969131678823|\n",
      "|          0.00|-2063.8969131678823|\n",
      "|          0.00|-2063.8969131678823|\n",
      "|          0.00|-2086.5995624395064|\n",
      "|          0.00|-2086.5995624395064|\n",
      "|          0.00| -781.4631257672772|\n",
      "|          0.00|-1811.9506855420864|\n",
      "|          0.00|-2063.8969131678823|\n",
      "|          0.00| -2132.004860982755|\n",
      "|          0.00|-1857.3559840853345|\n",
      "+--------------+-------------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "RMSE is 121897.8\n",
      "R^2 is 0.82886\n"
     ]
    }
   ],
   "source": [
    "def getEvaluationMetrics(pipelineModel,outputCol,testDF):\n",
    "    predDF = pipelineModel.transform(testDF)\n",
    "    predDF.select(outputCol, \"prediction\").show(10)\n",
    "\n",
    "    regressionEvaluator = RegressionEvaluator(\n",
    "    predictionCol=\"prediction\",\n",
    "    labelCol=outputCol,\n",
    "    metricName=\"rmse\")\n",
    "    rmse = regressionEvaluator.evaluate(predDF)\n",
    "\n",
    "    regressionEvaluator = RegressionEvaluator(\n",
    "    predictionCol=\"prediction\",\n",
    "    labelCol=outputCol,\n",
    "    metricName=\"r2\")\n",
    "    r2 = regressionEvaluator.evaluate(predDF)\n",
    "    \n",
    "    return rmse, r2\n",
    "\n",
    "evaluationMetrics = getEvaluationMetrics(pipelineModel,\"m2_total_spend\",testDF)\n",
    "print(f\"RMSE is {evaluationMetrics[0]:.1f}\")\n",
    "print(f\"R^2 is {evaluationMetrics[1]:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train linear regression model using log-transformed coefficients\n",
    "\n",
    "Now that we have used our new functions to test out the model accuracy on untransformed features and untransformed output, let's retrain the linear regression model on transformed features and/or transformed output (log scale). First we create these new features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------+--------------+---------------+------------------+----------------+------------------+-------------------+----------------------+--------------------+------------------+\n",
      "| user_id|m2_total_spend|m1_total_spend|m1_total_events|m1_purchase_events|m1_user_sessions|m1_total_spend_log|m1_total_events_log|m1_purchase_events_log|m1_user_sessions_log|m2_total_spend_log|\n",
      "+--------+--------------+--------------+---------------+------------------+----------------+------------------+-------------------+----------------------+--------------------+------------------+\n",
      "|22165363|          0.00|          0.00|              2|                 0|               2|-6.907755278982137| 0.6936470556015963|    -6.907755278982137|  0.6936470556015963|-6.907755278982137|\n",
      "|32978429|          0.00|          0.00|              8|                 0|               2|-6.907755278982137|  2.079566533867987|    -6.907755278982137|  0.6936470556015963|-6.907755278982137|\n",
      "+--------+--------------+--------------+---------------+------------------+----------------+------------------+-------------------+----------------------+--------------------+------------------+\n",
      "only showing top 2 rows\n",
      "\n",
      "+--------+--------------+--------------+---------------+------------------+----------------+------------------+--------------------+----------------------+--------------------+------------------+\n",
      "| user_id|m2_total_spend|m1_total_spend|m1_total_events|m1_purchase_events|m1_user_sessions|m1_total_spend_log| m1_total_events_log|m1_purchase_events_log|m1_user_sessions_log|m2_total_spend_log|\n",
      "+--------+--------------+--------------+---------------+------------------+----------------+------------------+--------------------+----------------------+--------------------+------------------+\n",
      "|29830839|          0.00|          0.00|              1|                 0|               1|-6.907755278982137|9.995003330834232E-4|    -6.907755278982137|9.995003330834232E-4|-6.907755278982137|\n",
      "|31198833|          0.00|          0.00|              1|                 0|               1|-6.907755278982137|9.995003330834232E-4|    -6.907755278982137|9.995003330834232E-4|-6.907755278982137|\n",
      "+--------+--------------+--------------+---------------+------------------+----------------+------------------+--------------------+----------------------+--------------------+------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainDF = trainDF \\\n",
    "          .withColumn(\"m1_total_spend_log\", log(col(\"m1_total_spend\")+0.001)) \\\n",
    "          .withColumn(\"m1_total_events_log\", log(col(\"m1_total_events\")+0.001)) \\\n",
    "          .withColumn(\"m1_purchase_events_log\", log(col(\"m1_purchase_events\")+0.001)) \\\n",
    "          .withColumn(\"m1_user_sessions_log\", log(col(\"m1_user_sessions\")+0.001)) \\\n",
    "          .withColumn(\"m2_total_spend_log\", log(col(\"m2_total_spend\")+0.001))\n",
    "\n",
    "testDF = testDF \\\n",
    "          .withColumn(\"m1_total_spend_log\", log(col(\"m1_total_spend\")+0.001)) \\\n",
    "          .withColumn(\"m1_total_events_log\", log(col(\"m1_total_events\")+0.001)) \\\n",
    "          .withColumn(\"m1_purchase_events_log\", log(col(\"m1_purchase_events\")+0.001)) \\\n",
    "          .withColumn(\"m1_user_sessions_log\", log(col(\"m1_user_sessions\")+0.001)) \\\n",
    "          .withColumn(\"m2_total_spend_log\", log(col(\"m2_total_spend\")+0.001))\n",
    "\n",
    "trainDF.show(2)\n",
    "testDF.show(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test out different combinations of log-transformed features and outputs\n",
    "\n",
    "Here we test out three additional transformations of the dataset in order to evaluate the linear regression model performance.\n",
    "\n",
    "Total tested model formulations:\n",
    "1. Normal inputs, normal output: `RMSE is 121897.8, R^2 is 0.82886`\n",
    "2. Log-transformed inputs, normal output: `RMSE is 292861.0, R^2 is 0.01218`\n",
    "3. Log-transformed inputs, log-transformed output: `RMSE is 3.1, R^2 is 0.20528` (note: cannot be compared to non-log-transformed outputs)\n",
    "4. Normal inputs, log-transformed output: `RMSE is 3.5, R^2 is 0.01118` (note: cannot be compared to non-log-transformed outputs)\n",
    "5. Normal and log-transformed inputs, normal output: `RMSE is 121674.3, R^2 is 0.82949`\n",
    "\n",
    "Due to the larger R^2 and smaller RMSE, we would suggest adopting the last model. Although linear regression does not take hyperparameters as such, we have made the pre-training choice to log-transform features and include them \n",
    "as well. In the future, it would be useful to do a more in-depth feature selection (perhaps a stepwise feature selection), and use AIC to determine model complexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Log-transformed inputs, normal output **\n",
      "Model coefficients\n",
      "              Column name    Coefficient\n",
      "0               intercept  460262.326282\n",
      "1      m1_total_spend_log  -89945.506680\n",
      "2     m1_total_events_log   12206.931534\n",
      "3  m1_purchase_events_log  158480.854321\n",
      "4    m1_user_sessions_log   -8806.028622\n",
      "+--------------+-------------------+\n",
      "|m2_total_spend|         prediction|\n",
      "+--------------+-------------------+\n",
      "|          0.00|-13159.683979370282|\n",
      "|          0.00|-13159.683979370282|\n",
      "|          0.00|-13159.683979370282|\n",
      "|          0.00| -10804.05689219205|\n",
      "|          0.00| -10804.05689219205|\n",
      "|          0.00|  771.1186771667562|\n",
      "|          0.00| -5856.605719513434|\n",
      "|          0.00|-13159.683979370282|\n",
      "|          0.00|  -8447.58053492289|\n",
      "|          0.00| -5724.292691155686|\n",
      "+--------------+-------------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "RMSE is 292861.0\n",
      "R^2 is 0.01218\n"
     ]
    }
   ],
   "source": [
    "print(\"** Log-transformed inputs, normal output **\")\n",
    "inputCols = [\"m1_total_spend_log\",\"m1_total_events_log\",\"m1_purchase_events_log\",\"m1_user_sessions_log\"]\n",
    "pipelineModel = generateLRModel(inputCols, \"m2_total_spend\", trainDF)\n",
    "\n",
    "print(\"Model coefficients\")\n",
    "print(modelInfo(inputCols, pipelineModel))\n",
    "\n",
    "evaluationMetrics = getEvaluationMetrics(pipelineModel,\"m2_total_spend\",testDF)\n",
    "print(f\"RMSE is {evaluationMetrics[0]:.1f}\")\n",
    "print(f\"R^2 is {evaluationMetrics[1]:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Log-transformed inputs, log-transformed output **\n",
      "Model coefficients\n",
      "              Column name  Coefficient\n",
      "0               intercept     1.503228\n",
      "1      m1_total_spend_log    -1.317085\n",
      "2     m1_total_events_log     0.920986\n",
      "3  m1_purchase_events_log     2.590074\n",
      "4    m1_user_sessions_log    -0.666778\n",
      "+------------------+-------------------+\n",
      "|m2_total_spend_log|         prediction|\n",
      "+------------------+-------------------+\n",
      "|-6.907755278982137| -7.290018879251713|\n",
      "|-6.907755278982137| -7.290018879251713|\n",
      "|-6.907755278982137| -7.290018879251713|\n",
      "|-6.907755278982137|-7.1139419292199975|\n",
      "|-6.907755278982137|-7.1139419292199975|\n",
      "|-6.907755278982137| -6.242802257791032|\n",
      "|-6.907755278982137| -6.740667570247851|\n",
      "|-6.907755278982137| -7.290018879251713|\n",
      "|-6.907755278982137| -6.937801498475139|\n",
      "|-6.907755278982137| -6.732335393060614|\n",
      "+------------------+-------------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "RMSE is 3.1\n",
      "R^2 is 0.20528\n"
     ]
    }
   ],
   "source": [
    "print(\"** Log-transformed inputs, log-transformed output **\")\n",
    "inputCols = [\"m1_total_spend_log\",\"m1_total_events_log\",\"m1_purchase_events_log\",\"m1_user_sessions_log\"]\n",
    "pipelineModel = generateLRModel(inputCols, \"m2_total_spend_log\", trainDF)\n",
    "\n",
    "print(\"Model coefficients\")\n",
    "print(modelInfo(inputCols, pipelineModel))\n",
    "\n",
    "evaluationMetrics = getEvaluationMetrics(pipelineModel,\"m2_total_spend_log\",testDF)\n",
    "print(f\"RMSE is {evaluationMetrics[0]:.1f}\")\n",
    "print(f\"R^2 is {evaluationMetrics[1]:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Normal inputs, log-transformed output **\n",
      "Model coefficients\n",
      "          Column name  Coefficient\n",
      "0           intercept    -6.116609\n",
      "1      m1_total_spend     0.000002\n",
      "2     m1_total_events     0.000767\n",
      "3  m1_purchase_events    -0.003722\n",
      "4    m1_user_sessions     0.002832\n",
      "+------------------+-------------------+\n",
      "|m2_total_spend_log|         prediction|\n",
      "+------------------+-------------------+\n",
      "|-6.907755278982137| -6.113010575597168|\n",
      "|-6.907755278982137| -6.113010575597168|\n",
      "|-6.907755278982137| -6.113010575597168|\n",
      "|-6.907755278982137| -6.109411936212896|\n",
      "|-6.907755278982137| -6.109411936212896|\n",
      "|-6.907755278982137|  -6.09478209746954|\n",
      "|-6.907755278982137| -6.108645152094788|\n",
      "|-6.907755278982137| -6.113010575597168|\n",
      "|-6.907755278982137| -6.102214657444352|\n",
      "|-6.907755278982137|-6.1014478733262445|\n",
      "+------------------+-------------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "RMSE is 3.5\n",
      "R^2 is 0.01118\n"
     ]
    }
   ],
   "source": [
    "print(\"** Normal inputs, log-transformed output **\")\n",
    "inputCols = [\"m1_total_spend\",\"m1_total_events\",\"m1_purchase_events\",\"m1_user_sessions\"]\n",
    "pipelineModel = generateLRModel(inputCols, \"m2_total_spend_log\", trainDF)\n",
    "\n",
    "print(\"Model coefficients\")\n",
    "print(modelInfo(inputCols, pipelineModel))\n",
    "\n",
    "evaluationMetrics = getEvaluationMetrics(pipelineModel,\"m2_total_spend_log\",testDF)\n",
    "print(f\"RMSE is {evaluationMetrics[0]:.1f}\")\n",
    "print(f\"R^2 is {evaluationMetrics[1]:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Normal and log-transformed inputs, normal output **\n",
      "Model coefficients\n",
      "              Column name  Coefficient\n",
      "0               intercept  1791.628848\n",
      "1          m1_total_spend     5.122784\n",
      "2         m1_total_events   275.439568\n",
      "3      m1_purchase_events -1428.450224\n",
      "4        m1_user_sessions  -285.095136\n",
      "5      m1_total_spend_log   371.336103\n",
      "6     m1_total_events_log -2251.076418\n",
      "7  m1_purchase_events_log  -334.958025\n",
      "8    m1_user_sessions_log  -614.021730\n",
      "+--------------+-------------------+\n",
      "|m2_total_spend|         prediction|\n",
      "+--------------+-------------------+\n",
      "|          0.00| 1527.8187484631812|\n",
      "|          0.00| 1527.8187484631812|\n",
      "|          0.00| 1527.8187484631812|\n",
      "|          0.00| -466.3400480942919|\n",
      "|          0.00| -466.3400480942919|\n",
      "|          0.00|-3302.6147649497266|\n",
      "|          0.00|-1103.2584007598834|\n",
      "|          0.00| 1527.8187484631812|\n",
      "|          0.00| -2470.869882475308|\n",
      "|          0.00|-2697.6309727164603|\n",
      "+--------------+-------------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "RMSE is 121674.3\n",
      "R^2 is 0.82949\n"
     ]
    }
   ],
   "source": [
    "print(\"** Normal and log-transformed inputs, normal output **\")\n",
    "inputCols = [\"m1_total_spend\",\"m1_total_events\",\"m1_purchase_events\",\"m1_user_sessions\",\n",
    "             \"m1_total_spend_log\",\"m1_total_events_log\",\"m1_purchase_events_log\",\"m1_user_sessions_log\"]\n",
    "pipelineModel = generateLRModel(inputCols, \"m2_total_spend\", trainDF)\n",
    "\n",
    "print(\"Model coefficients\")\n",
    "print(modelInfo(inputCols, pipelineModel))\n",
    "\n",
    "evaluationMetrics = getEvaluationMetrics(pipelineModel,\"m2_total_spend\",testDF)\n",
    "print(f\"RMSE is {evaluationMetrics[0]:.1f}\")\n",
    "print(f\"R^2 is {evaluationMetrics[1]:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save pipeline model and get model size\n",
    "\n",
    "The model size is 14.0 kB, according to the file explorer in Linux."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelinePath = \"models/lr-pipeline-model\"\n",
    "pipelineModel.write().overwrite().save(pipelinePath)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DS 5110 Spark 3.1",
   "language": "python",
   "name": "ds5110_spark3.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
