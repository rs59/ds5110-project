{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File 07 - Random Forest\n",
    "\n",
    "##### Group 12:\n",
    "\n",
    "##### Hannah Schmuckler, mmc4cv\n",
    "\n",
    "##### Rob Schwartz, res7cd\n",
    "\n",
    "In this file, we create an ML pipeline based on the output from File 02 (Feature creation).\n",
    "\n",
    "The files needed are `/processed_data/train.parquet` and `/processed_data/test.parquet`.\n",
    "\n",
    "We create a random forest model and fine-tune. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up Spark session\n",
    "\n",
    "We can specify more options in the SparkSession creator, but currently the options are at the default settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 503 ms, sys: 421 ms, total: 925 ms\n",
      "Wall time: 5.71 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import types as T\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "from pyspark.mllib.util import MLUtils\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.functions import log\n",
    "from pyspark.ml.stat import Correlation\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "        .appName(\"project\") \\\n",
    "        .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in dataframes for train and test sets\n",
    "\n",
    "This data should have been previously generated: we can find it in the `processed_data` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------------+-----------------+------------+--------------+------------------+------------------+----------------------------+---------------------------+----------------------------+----------------------------+------------------------+------------------------+-------------------------+------------------------+-----------+---------------+-----------+----------------------+------------------+------------------+-------------------------+---------------------+------------------+------------------+--------------------+------------------+------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|  user_id|     T_total_spend|      total_spend|total_events|total_sessions|avg_session_length| sd_session_length|avg_interactions_per_session|sd_interactions_per_session|max_interactions_per_session|purchase_pct_of_total_events|view_pct_of_total_events|cart_pct_of_total_events|avg_purchases_per_session|sd_purchases_per_session|cart_events|purchase_events|view_events|sessions_with_purchase|sessions_with_cart|sessions_with_view|pct_sessions_end_purchase|pct_sessions_end_cart|   total_spend_log|  total_events_log| purchase_events_log|total_sessions_log| T_total_spend_log|     pca_purchases10|     pca_purchases20|     pca_purchases50|    pca_purchases100|\n",
      "+---------+------------------+-----------------+------------+--------------+------------------+------------------+----------------------------+---------------------------+----------------------------+----------------------------+------------------------+------------------------+-------------------------+------------------------+-----------+---------------+-----------+----------------------+------------------+------------------+-------------------------+---------------------+------------------+------------------+--------------------+------------------+------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|512424146|11270.879859924316|526.6399841308594|         288|             7| 260.7142857142857|262.34564622885983|           5.142857142857143|         2.4784787961282104|                           8|         0.08333333333333333|      0.7777777777777778|      0.1388888888888889|      0.42857142857142855|      0.5345224838248488|          5|              3|         28|                     3|                 4|                 7|      0.42857142857142855|  0.14285714285714285| 6.266519071855391|  5.66296395235214|  1.0989455664582302|1.9460529959950605| 9.329977763688856|[-0.0221225462344...|[-0.0221225462344...|[-0.0221225462344...|[-0.0221225462344...|\n",
      "|512440689|               0.0|640.9400024414062|         113|            16|           566.875| 711.0573230525557|                      7.0625|          6.060459278525569|                          17|        0.008849557522123894|      0.9734513274336283|    0.017699115044247787|                   0.0625|     0.24999999999999997|          2|              1|        110|                     1|                 1|                16|                   0.0625|                  0.0|  6.46293741281174| 4.727396668230706|9.995003330834232E-4|2.7726512202867375|-6.907755278982137|[4.69075176148694...|[4.69075176148694...|[4.69075176148694...|[4.69075176148694...|\n",
      "|512467274| 1532.799949645996|39.90000057220459|          30|             6|39.166666666666664| 75.29785300170694|          1.6666666666666667|         1.2110601416389968|                           4|                         0.1|                     0.8|                     0.1|      0.16666666666666666|       0.408248290463863|          1|              1|          8|                     1|                 1|                 6|      0.16666666666666666|                  0.0| 3.686401400579004|3.4012307144399454|9.995003330834232E-4|1.7919261220073759| 7.334852026766245|[-6.0647773396890...|[-6.0647773396890...|[-6.0647773396890...|[-6.0647773396890...|\n",
      "|512470083|               0.0|385.8500061035156|          16|             5|             101.0|  72.8800384193093|                         3.2|         1.3038404810405297|                           4|                      0.0625|                    0.75|                  0.1875|                      0.2|      0.4472135954999579|          3|              1|         12|                     1|                 3|                 5|                      0.2|                  0.4| 5.955451300399281|2.7726512202867375|9.995003330834232E-4|1.6096378924367667|-6.907755278982137|[-0.0053959415183...|[-0.0053959415183...|[-0.0053959415183...|[-0.0053959415183...|\n",
      "|512474045|               0.0|370.6499938964844|          29|             6|237.16666666666666|229.47541625774787|           4.833333333333333|         2.7141603981096374|                           9|         0.06896551724137931|      0.8620689655172413|     0.06896551724137931|       0.3333333333333333|      0.5163977794943222|          2|              2|         25|                     2|                 2|                 6|       0.3333333333333333|                  0.0|5.9152609025951115| 3.367330312150578|  0.6936470556015963|1.7919261220073759|-6.907755278982137|[-1.9975955387030...|[-1.9975955387030...|[-1.9975955387030...|[-1.9975955387030...|\n",
      "+---------+------------------+-----------------+------------+--------------+------------------+------------------+----------------------------+---------------------------+----------------------------+----------------------------+------------------------+------------------------+-------------------------+------------------------+-----------+---------------+-----------+----------------------+------------------+------------------+-------------------------+---------------------+------------------+------------------+--------------------+------------------+------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "CPU times: user 3.88 ms, sys: 3.03 ms, total: 6.91 ms\n",
      "Wall time: 5.18 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "trainDF = spark.read.parquet(\"./processed_data/train.parquet\")\n",
    "testDF = spark.read.parquet(\"./processed_data/test.parquet\")\n",
    "trainDF.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up Spark ML pipeline training for random forest\n",
    "\n",
    "We create the function `generatePipeline(inputCols, outputCol)`, Then, we train the pipeline using this function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4 µs, sys: 0 ns, total: 4 µs\n",
      "Wall time: 6.68 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def generatePipeline(inputCols, outputCol):\n",
    "    \n",
    "    # Select input columns for random forest regression\n",
    "    vecAssembler = VectorAssembler(inputCols=inputCols, outputCol=\"features\")\n",
    "\n",
    "    # Select output column for random forest regression\n",
    "    rf = RandomForestRegressor(featuresCol=\"features\", labelCol=outputCol, seed = 42)#, numTrees=5, maxDepth=5)\n",
    "    \n",
    "    pipeline = Pipeline(stages=[vecAssembler, rf])\n",
    "    return pipeline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate adjusted r2 (https://towardsdatascience.com/machine-learning-linear-regression-using-pyspark-9d5d5c772b42)\n",
    "def adj_r2(r2, inputCols, testDF):\n",
    "    n = testDF.count()\n",
    "    p = len(inputCols)\n",
    "    adjusted_r2 = 1-(((1-r2)*(n-1))/(n-p-1))\n",
    "    return adjusted_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getEvaluationMetrics(pipelineMode,outputCol,testDF,inputCols):\n",
    "    predDF = pipelineModel.transform(testDF)\n",
    "    predDF.select(outputCol, \"prediction\").show(10)\n",
    "    \n",
    "    regressionEvaluator = RegressionEvaluator(\n",
    "    predictionCol=\"prediction\",\n",
    "    labelCol=outputCol,\n",
    "    metricName=\"rmse\")\n",
    "    rmse = regressionEvaluator.evaluate(predDF)\n",
    "\n",
    "    regressionEvaluator = RegressionEvaluator(\n",
    "    predictionCol=\"prediction\",\n",
    "    labelCol=outputCol,\n",
    "    metricName=\"r2\")\n",
    "    r2 = regressionEvaluator.evaluate(predDF)\n",
    "    \n",
    "    # Manually calculate Adjusted r2\n",
    "    adjusted_r2 = adj_r2(r2, inputCols, testDF)\n",
    "    \n",
    "    return rmse, r2, adjusted_r2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelInfo(inputCols, pipelineModel):\n",
    "    modelCols = pipelineModel.stages[-2].getInputCols()\n",
    "    \n",
    "    feature_importance = pipelineModel.stages[-1].featureImportances\n",
    "    \n",
    "    return pd.DataFrame(list(zip(modelCols, feature_importance)), columns = ['Column name', 'Importance']).sort_values(by=\"Importance\", ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** All normal inputs, normal output **\n",
      "                     Column name  Importance\n",
      "1                   total_events    0.496159\n",
      "0                    total_spend    0.268796\n",
      "13        sessions_with_purchase    0.050056\n",
      "14            sessions_with_cart    0.041980\n",
      "7   purchase_pct_of_total_events    0.029680\n",
      "2                purchase_events    0.028271\n",
      "15            sessions_with_view    0.015511\n",
      "8       view_pct_of_total_events    0.014895\n",
      "12                   view_events    0.013449\n",
      "3                 total_sessions    0.008379\n",
      "11                   cart_events    0.007676\n",
      "16     pct_sessions_end_purchase    0.005491\n",
      "9       cart_pct_of_total_events    0.005483\n",
      "10     avg_purchases_per_session    0.003669\n",
      "6   max_interactions_per_session    0.003664\n",
      "17         pct_sessions_end_cart    0.001570\n",
      "20      sd_purchases_per_session    0.001437\n",
      "19   sd_interactions_per_session    0.001403\n",
      "4             avg_session_length    0.000941\n",
      "18             sd_session_length    0.000930\n",
      "5   avg_interactions_per_session    0.000561\n",
      "+-----------------+------------------+\n",
      "|    T_total_spend|        prediction|\n",
      "+-----------------+------------------+\n",
      "|              0.0| 2550.801865990343|\n",
      "|              0.0|  4569.91567442321|\n",
      "|              0.0| 8058.642642633907|\n",
      "|              0.0|   2565.6191753586|\n",
      "|              0.0|3120.9264389253485|\n",
      "|              0.0| 2280.960214433336|\n",
      "|              0.0| 3462.248922600446|\n",
      "|              0.0|3120.9264389253485|\n",
      "|79118.00024795532| 118382.5885379852|\n",
      "|663.1999969482422|2539.8457361223745|\n",
      "+-----------------+------------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "RMSE is 49677.1\n",
      "R^2 is 0.49658\n",
      "Adjusted R^2 is 0.49643\n"
     ]
    }
   ],
   "source": [
    "print(\"** All normal inputs, normal output **\")\n",
    "inputCols = [\"total_spend\",\"total_events\",\"purchase_events\", \"total_sessions\", \"avg_session_length\", \"avg_interactions_per_session\", \"max_interactions_per_session\",\n",
    "             \"purchase_pct_of_total_events\", \"view_pct_of_total_events\", \"cart_pct_of_total_events\",\"avg_purchases_per_session\", \"cart_events\",\n",
    "             \"view_events\", \"sessions_with_purchase\", \"sessions_with_cart\",\"sessions_with_view\", \"pct_sessions_end_purchase\", \"pct_sessions_end_cart\", 'sd_session_length', \n",
    "             'sd_interactions_per_session', 'sd_purchases_per_session']\n",
    "\n",
    "outputCol = \"T_total_spend\"\n",
    "\n",
    "pipeline = generatePipeline(inputCols, outputCol)\n",
    "pipelineModel = pipeline.fit(trainDF)\n",
    "\n",
    "print(modelInfo(inputCols, pipelineModel))\n",
    "\n",
    "evaluationMetrics = getEvaluationMetrics(pipelineModel,outputCol,testDF, inputCols)\n",
    "print(f\"RMSE is {evaluationMetrics[0]:.1f}\")\n",
    "print(f\"R^2 is {evaluationMetrics[1]:.5f}\")\n",
    "print(f\"Adjusted R^2 is {evaluationMetrics[2]:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** All normal inputs + log inputs (25 total), normal output **\n",
      "                     Column name  Importance\n",
      "1                   total_events    0.392177\n",
      "21               total_spend_log    0.183318\n",
      "22              total_events_log    0.145389\n",
      "0                    total_spend    0.134207\n",
      "7   purchase_pct_of_total_events    0.041035\n",
      "8       view_pct_of_total_events    0.019149\n",
      "12                   view_events    0.012591\n",
      "2                purchase_events    0.009776\n",
      "13        sessions_with_purchase    0.009383\n",
      "10     avg_purchases_per_session    0.008511\n",
      "14            sessions_with_cart    0.008126\n",
      "16     pct_sessions_end_purchase    0.007888\n",
      "9       cart_pct_of_total_events    0.006889\n",
      "3                 total_sessions    0.005107\n",
      "15            sessions_with_view    0.002572\n",
      "24            total_sessions_log    0.002305\n",
      "17         pct_sessions_end_cart    0.002038\n",
      "20      sd_purchases_per_session    0.001948\n",
      "6   max_interactions_per_session    0.001811\n",
      "19   sd_interactions_per_session    0.001736\n",
      "5   avg_interactions_per_session    0.001363\n",
      "23           purchase_events_log    0.001274\n",
      "11                   cart_events    0.000711\n",
      "4             avg_session_length    0.000520\n",
      "18             sd_session_length    0.000174\n",
      "+-----------------+------------------+\n",
      "|    T_total_spend|        prediction|\n",
      "+-----------------+------------------+\n",
      "|              0.0|2027.6430647984303|\n",
      "|              0.0| 4548.556883033745|\n",
      "|              0.0| 6168.147137854566|\n",
      "|              0.0| 1685.765179656634|\n",
      "|              0.0|1958.5846390024021|\n",
      "|              0.0| 1685.765179656634|\n",
      "|              0.0|1547.4637709973642|\n",
      "|              0.0| 1884.164446603374|\n",
      "|79118.00024795532|131851.54168496624|\n",
      "|663.1999969482422|1903.8848613402101|\n",
      "+-----------------+------------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "RMSE is 48522.6\n",
      "R^2 is 0.51971\n",
      "Adjusted R^2 is 0.51954\n"
     ]
    }
   ],
   "source": [
    "print(\"** All normal inputs + log inputs (25 total), normal output **\")\n",
    "inputCols = [\"total_spend\",\"total_events\",\"purchase_events\", \"total_sessions\", \"avg_session_length\", \"avg_interactions_per_session\", \"max_interactions_per_session\",\n",
    "             \"purchase_pct_of_total_events\", \"view_pct_of_total_events\", \"cart_pct_of_total_events\",\"avg_purchases_per_session\", \"cart_events\", \n",
    "             \"view_events\", \"sessions_with_purchase\", \"sessions_with_cart\",\"sessions_with_view\", \"pct_sessions_end_purchase\", \"pct_sessions_end_cart\", 'sd_session_length', \n",
    "             'sd_interactions_per_session', 'sd_purchases_per_session', 'total_spend_log', 'total_events_log', 'purchase_events_log', 'total_sessions_log']\n",
    "\n",
    "outputCol = \"T_total_spend\"\n",
    "\n",
    "pipeline = generatePipeline(inputCols, outputCol)\n",
    "pipelineModel = pipeline.fit(trainDF)\n",
    "\n",
    "print(modelInfo(inputCols, pipelineModel))\n",
    "\n",
    "evaluationMetrics = getEvaluationMetrics(pipelineModel,outputCol,testDF, inputCols)\n",
    "print(f\"RMSE is {evaluationMetrics[0]:.1f}\")\n",
    "print(f\"R^2 is {evaluationMetrics[1]:.5f}\")\n",
    "print(f\"Adjusted R^2 is {evaluationMetrics[2]:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interesting - adding the log columns seems to have split the importance of their corresponding non-log inputs, but has increased the adjusted r^2 by approximately 1.5. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** All normal inputs + log inputs, log output **\n",
      "                     Column name  Importance\n",
      "1                   total_events    0.215407\n",
      "21               total_spend_log    0.210539\n",
      "22              total_events_log    0.149537\n",
      "0                    total_spend    0.148796\n",
      "12                   view_events    0.142919\n",
      "2                purchase_events    0.022436\n",
      "23           purchase_events_log    0.020274\n",
      "7   purchase_pct_of_total_events    0.020154\n",
      "13        sessions_with_purchase    0.013405\n",
      "6   max_interactions_per_session    0.011910\n",
      "15            sessions_with_view    0.010489\n",
      "3                 total_sessions    0.007956\n",
      "18             sd_session_length    0.006692\n",
      "11                   cart_events    0.005487\n",
      "24            total_sessions_log    0.005112\n",
      "19   sd_interactions_per_session    0.003684\n",
      "4             avg_session_length    0.001849\n",
      "5   avg_interactions_per_session    0.001203\n",
      "14            sessions_with_cart    0.000837\n",
      "20      sd_purchases_per_session    0.000748\n",
      "10     avg_purchases_per_session    0.000341\n",
      "9       cart_pct_of_total_events    0.000176\n",
      "8       view_pct_of_total_events    0.000048\n",
      "16     pct_sessions_end_purchase    0.000000\n",
      "17         pct_sessions_end_cart    0.000000\n",
      "+------------------+-------------------+\n",
      "| T_total_spend_log|         prediction|\n",
      "+------------------+-------------------+\n",
      "|-6.907755278982137| -3.848979105544971|\n",
      "|-6.907755278982137| -3.568050030588144|\n",
      "|-6.907755278982137|-2.9154942740687853|\n",
      "|-6.907755278982137| -4.882171945543101|\n",
      "|-6.907755278982137| -4.636802433051648|\n",
      "|-6.907755278982137|-4.7118281701489995|\n",
      "|-6.907755278982137| -4.416689782520154|\n",
      "|-6.907755278982137| -4.066983758763179|\n",
      "|11.278695703691795| 11.337976156626432|\n",
      "|6.4970781070591626|0.45624415032273785|\n",
      "+------------------+-------------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "RMSE is 5.2\n",
      "R^2 is 0.46308\n",
      "Adjusted R^2 is 0.46289\n"
     ]
    }
   ],
   "source": [
    "print(\"** All normal inputs + log inputs, log output **\")\n",
    "inputCols = [\"total_spend\",\"total_events\",\"purchase_events\", \"total_sessions\", \"avg_session_length\", \"avg_interactions_per_session\", \"max_interactions_per_session\",\n",
    "             \"purchase_pct_of_total_events\", \"view_pct_of_total_events\", \"cart_pct_of_total_events\",\"avg_purchases_per_session\", \"cart_events\", \n",
    "             \"view_events\", \"sessions_with_purchase\", \"sessions_with_cart\",\"sessions_with_view\", \"pct_sessions_end_purchase\", \"pct_sessions_end_cart\", 'sd_session_length', \n",
    "             'sd_interactions_per_session', 'sd_purchases_per_session', 'total_spend_log', 'total_events_log', 'purchase_events_log', 'total_sessions_log']\n",
    "\n",
    "outputCol = \"T_total_spend_log\"\n",
    "\n",
    "pipeline = generatePipeline(inputCols, outputCol)\n",
    "pipelineModel = pipeline.fit(trainDF)\n",
    "\n",
    "print(modelInfo(inputCols, pipelineModel))\n",
    "\n",
    "evaluationMetrics = getEvaluationMetrics(pipelineModel,outputCol,testDF, inputCols)\n",
    "print(f\"RMSE is {evaluationMetrics[0]:.1f}\")\n",
    "print(f\"R^2 is {evaluationMetrics[1]:.5f}\")\n",
    "print(f\"Adjusted R^2 is {evaluationMetrics[2]:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Log output is not the way to go for this model either. \n",
    "\n",
    "#### Can we improve adg r-square by tuning predictors? Yes. It turns out that removing sd_session_length improves the R^2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Tuned inputs, normal output **\n",
      "                     Column name  Importance\n",
      "1                   total_events    0.315854\n",
      "21              total_events_log    0.206459\n",
      "20               total_spend_log    0.186679\n",
      "0                    total_spend    0.138182\n",
      "7   purchase_pct_of_total_events    0.042733\n",
      "8       view_pct_of_total_events    0.017886\n",
      "12                   view_events    0.015309\n",
      "2                purchase_events    0.014784\n",
      "16     pct_sessions_end_purchase    0.011693\n",
      "13        sessions_with_purchase    0.009729\n",
      "9       cart_pct_of_total_events    0.008567\n",
      "10     avg_purchases_per_session    0.006986\n",
      "11                   cart_events    0.005369\n",
      "23            total_sessions_log    0.004449\n",
      "3                 total_sessions    0.003977\n",
      "19      sd_purchases_per_session    0.002283\n",
      "22           purchase_events_log    0.002095\n",
      "18   sd_interactions_per_session    0.001740\n",
      "6   max_interactions_per_session    0.001733\n",
      "14            sessions_with_cart    0.001337\n",
      "5   avg_interactions_per_session    0.000869\n",
      "15            sessions_with_view    0.000822\n",
      "4             avg_session_length    0.000425\n",
      "17         pct_sessions_end_cart    0.000038\n",
      "+-----------------+------------------+\n",
      "|    T_total_spend|        prediction|\n",
      "+-----------------+------------------+\n",
      "|              0.0|1864.7299641851084|\n",
      "|              0.0| 3562.433495313536|\n",
      "|              0.0| 5842.195265160792|\n",
      "|              0.0| 1714.991257577766|\n",
      "|              0.0|1873.8510219410432|\n",
      "|              0.0|1624.4160360869046|\n",
      "|              0.0|1717.1925839289931|\n",
      "|              0.0|1864.7299641851084|\n",
      "|79118.00024795532| 128152.3061112802|\n",
      "|663.1999969482422|2042.4170159527082|\n",
      "+-----------------+------------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "RMSE is 48351.2\n",
      "R^2 is 0.52310\n",
      "Adjusted R^2 is 0.52293\n"
     ]
    }
   ],
   "source": [
    "print(\"** Tuned inputs, normal output **\")\n",
    "inputCols = [\"total_spend\",\"total_events\",\"purchase_events\", \"total_sessions\", \"avg_session_length\", \"avg_interactions_per_session\", \"max_interactions_per_session\",\n",
    "             \"purchase_pct_of_total_events\", \"view_pct_of_total_events\", \"cart_pct_of_total_events\",\"avg_purchases_per_session\", \"cart_events\", \n",
    "             \"view_events\", \"sessions_with_purchase\", \"sessions_with_cart\",\"sessions_with_view\", \"pct_sessions_end_purchase\", \"pct_sessions_end_cart\", \n",
    "             'sd_interactions_per_session', 'sd_purchases_per_session', 'total_spend_log', 'total_events_log', 'purchase_events_log', 'total_sessions_log']\n",
    "\n",
    "outputCol = \"T_total_spend\"\n",
    "\n",
    "pipeline = generatePipeline(inputCols, outputCol)\n",
    "pipelineModel = pipeline.fit(trainDF)\n",
    "\n",
    "print(modelInfo(inputCols, pipelineModel))\n",
    "\n",
    "evaluationMetrics = getEvaluationMetrics(pipelineModel,outputCol,testDF, inputCols)\n",
    "print(f\"RMSE is {evaluationMetrics[0]:.1f}\")\n",
    "print(f\"R^2 is {evaluationMetrics[1]:.5f}\")\n",
    "print(f\"Adjusted R^2 is {evaluationMetrics[2]:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How can we do with only a few predictors? Much more computationally efficient!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** 7 predictors, normal output **\n",
      "           Column name  Importance\n",
      "1         total_events    0.366643\n",
      "4     total_events_log    0.279050\n",
      "3      total_spend_log    0.154637\n",
      "0          total_spend    0.121474\n",
      "6          view_events    0.038532\n",
      "5  purchase_events_log    0.031764\n",
      "2      purchase_events    0.007900\n",
      "+-----------------+------------------+\n",
      "|    T_total_spend|        prediction|\n",
      "+-----------------+------------------+\n",
      "|              0.0| 1625.740230559058|\n",
      "|              0.0| 5473.763240887481|\n",
      "|              0.0| 5348.133433025998|\n",
      "|              0.0| 1074.849415024602|\n",
      "|              0.0| 1305.673974874158|\n",
      "|              0.0| 1074.849415024602|\n",
      "|              0.0| 1074.849415024602|\n",
      "|              0.0|1494.5617479304678|\n",
      "|79118.00024795532| 137855.7158498556|\n",
      "|663.1999969482422| 1305.673974874158|\n",
      "+-----------------+------------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "RMSE is 48641.8\n",
      "R^2 is 0.51735\n",
      "Adjusted R^2 is 0.51730\n"
     ]
    }
   ],
   "source": [
    "print(\"** Minimized, normal output **\")\n",
    "inputCols = [\"total_spend\",\"total_events\",\"purchase_events\", 'total_spend_log', 'total_events_log', 'purchase_events_log','view_events']\n",
    "\n",
    "outputCol = \"T_total_spend\"\n",
    "\n",
    "pipeline = generatePipeline(inputCols, outputCol)\n",
    "pipelineModel = pipeline.fit(trainDF)\n",
    "\n",
    "print(modelInfo(inputCols, pipelineModel))\n",
    "\n",
    "evaluationMetrics = getEvaluationMetrics(pipelineModel,outputCol,testDF, inputCols)\n",
    "print(f\"RMSE is {evaluationMetrics[0]:.1f}\")\n",
    "print(f\"R^2 is {evaluationMetrics[1]:.5f}\")\n",
    "print(f\"Adjusted R^2 is {evaluationMetrics[2]:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The maximum achievable adjusted r-square seems to be 0.52293, with 23 predictors. However, it is possible to achieve an adjusted r-square of 0.51730 with just 7 predictors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test out different combinations of hyperparameters on minimized model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 25 ms, sys: 7.2 ms, total: 32.2 ms\n",
      "Wall time: 2.13 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "inputCols = [\"total_spend\",\"total_events\",\"purchase_events\", 'total_spend_log', 'total_events_log', 'purchase_events_log','view_events']\n",
    "\n",
    "outputCol = \"T_total_spend\"\n",
    "\n",
    "pipeline = generatePipeline(inputCols, outputCol)\n",
    "pipelineModel = pipeline.fit(trainDF)\n",
    "\n",
    "vecAssembler = VectorAssembler(inputCols=inputCols, outputCol=\"features\")\n",
    "\n",
    "rf = RandomForestRegressor(featuresCol=\"features\", labelCol=outputCol)\n",
    "\n",
    "pipeline = Pipeline(stages=[vecAssembler, rf])\n",
    "\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(rf.numTrees, [5, 10, 20]) \\\n",
    "    .addGrid(rf.maxDepth, [2, 4, 10]) \\\n",
    "    .addGrid(rf.featureSubsetStrategy, ['sqrt', 'log2', 'onethird']) \\\n",
    "    .build()\n",
    "\n",
    "crossval = CrossValidator(estimator=pipeline,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=RegressionEvaluator().setLabelCol(\"T_total_spend\"),\n",
    "                          numFolds=4)\n",
    "\n",
    "# Run cross-validation, and choose the best set of parameters.\n",
    "#cvModel = crossval.fit(trainDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.48 s, sys: 1.64 s, total: 7.12 s\n",
      "Wall time: 3min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cvModel = crossval.fit(trainDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{Param(parent='RandomForestRegressor_480fb57e65a5', name='numTrees', doc='Number of trees to train (>= 1).'): 5, Param(parent='RandomForestRegressor_480fb57e65a5', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 2, Param(parent='RandomForestRegressor_480fb57e65a5', name='featureSubsetStrategy', doc=\"The number of features to consider for splits at each tree node. Supported options: 'auto' (choose automatically for task: If numTrees == 1, set to 'all'. If numTrees > 1 (forest), set to 'sqrt' for classification and to 'onethird' for regression), 'all' (use all features), 'onethird' (use 1/3 of the features), 'sqrt' (use sqrt(number of features)), 'log2' (use log2(number of features)), 'n' (when n is in the range (0, 1.0], use n * number of features. When n is in the range (1, number of features), use n features). default = 'auto'\"): 'sqrt'}\n",
      "+-----------------+------------------+\n",
      "|    T_total_spend|        prediction|\n",
      "+-----------------+------------------+\n",
      "|              0.0| 1625.740230559058|\n",
      "|              0.0| 5473.763240887481|\n",
      "|              0.0| 5348.133433025998|\n",
      "|              0.0| 1074.849415024602|\n",
      "|              0.0| 1305.673974874158|\n",
      "|              0.0| 1074.849415024602|\n",
      "|              0.0| 1074.849415024602|\n",
      "|              0.0|1494.5617479304678|\n",
      "|79118.00024795532| 137855.7158498556|\n",
      "|663.1999969482422| 1305.673974874158|\n",
      "+-----------------+------------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "RMSE is 48641.8\n",
      "R^2 is 0.51735\n",
      "Adjusted R^2 is 0.51730\n"
     ]
    }
   ],
   "source": [
    "print()\n",
    "print(cvModel.getEstimatorParamMaps()[np.argmax(cvModel.avgMetrics)])\n",
    "\n",
    "evaluationMetrics = getEvaluationMetrics(cvModel.bestModel,\"T_total_spend\",testDF,inputCols)\n",
    "print(f\"RMSE is {evaluationMetrics[0]:.1f}\")\n",
    "print(f\"R^2 is {evaluationMetrics[1]:.5f}\")\n",
    "print(f\"Adjusted R^2 is {evaluationMetrics[2]:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test out different combinations of hyperparameters on best adj-r-square model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 22.4 ms, sys: 3.32 ms, total: 25.7 ms\n",
      "Wall time: 2.39 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "inputCols = [\"total_spend\",\"total_events\",\"purchase_events\", \"total_sessions\", \"avg_session_length\", \"avg_interactions_per_session\", \"max_interactions_per_session\",\n",
    "             \"purchase_pct_of_total_events\", \"view_pct_of_total_events\", \"cart_pct_of_total_events\",\"avg_purchases_per_session\", \"cart_events\", \n",
    "             \"view_events\", \"sessions_with_purchase\", \"sessions_with_cart\",\"sessions_with_view\", \"pct_sessions_end_purchase\", \"pct_sessions_end_cart\", \n",
    "             'sd_interactions_per_session', 'sd_purchases_per_session', 'total_spend_log', 'total_events_log', 'purchase_events_log', 'total_sessions_log']\n",
    "\n",
    "\n",
    "outputCol = \"T_total_spend\"\n",
    "\n",
    "pipeline = generatePipeline(inputCols, outputCol)\n",
    "pipelineModel = pipeline.fit(trainDF)\n",
    "\n",
    "vecAssembler = VectorAssembler(inputCols=inputCols, outputCol=\"features\")\n",
    "\n",
    "rf = RandomForestRegressor(featuresCol=\"features\", labelCol=outputCol)\n",
    "\n",
    "pipeline = Pipeline(stages=[vecAssembler, rf])\n",
    "\n",
    "#Set parameters to test\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(rf.numTrees, [5, 10, 20]) \\\n",
    "    .addGrid(rf.maxDepth, [2, 4, 10]) \\\n",
    "    .addGrid(rf.featureSubsetStrategy, ['sqrt', 'log2', 'onethird']) \\\n",
    "    .build()\n",
    "\n",
    "crossval = CrossValidator(estimator=pipeline,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=RegressionEvaluator().setLabelCol(\"T_total_spend\"),\n",
    "                          numFolds=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.86 s, sys: 1.85 s, total: 7.71 s\n",
      "Wall time: 4min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cvModel = crossval.fit(trainDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{Param(parent='RandomForestRegressor_4a5f0be87ebf', name='numTrees', doc='Number of trees to train (>= 1).'): 10, Param(parent='RandomForestRegressor_4a5f0be87ebf', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 2, Param(parent='RandomForestRegressor_4a5f0be87ebf', name='featureSubsetStrategy', doc=\"The number of features to consider for splits at each tree node. Supported options: 'auto' (choose automatically for task: If numTrees == 1, set to 'all'. If numTrees > 1 (forest), set to 'sqrt' for classification and to 'onethird' for regression), 'all' (use all features), 'onethird' (use 1/3 of the features), 'sqrt' (use sqrt(number of features)), 'log2' (use log2(number of features)), 'n' (when n is in the range (0, 1.0], use n * number of features. When n is in the range (1, number of features), use n features). default = 'auto'\"): 'sqrt'}\n",
      "+-----------------+------------------+\n",
      "|    T_total_spend|        prediction|\n",
      "+-----------------+------------------+\n",
      "|              0.0|1864.7299641851084|\n",
      "|              0.0| 3562.433495313536|\n",
      "|              0.0| 5842.195265160792|\n",
      "|              0.0| 1714.991257577766|\n",
      "|              0.0|1873.8510219410432|\n",
      "|              0.0|1624.4160360869046|\n",
      "|              0.0|1717.1925839289931|\n",
      "|              0.0|1864.7299641851084|\n",
      "|79118.00024795532| 128152.3061112802|\n",
      "|663.1999969482422|2042.4170159527082|\n",
      "+-----------------+------------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "RMSE is 48351.2\n",
      "R^2 is 0.52310\n",
      "Adjusted R^2 is 0.52293\n"
     ]
    }
   ],
   "source": [
    "print()\n",
    "print(cvModel.getEstimatorParamMaps()[np.argmax(cvModel.avgMetrics)])\n",
    "\n",
    "evaluationMetrics = getEvaluationMetrics(cvModel.bestModel,\"T_total_spend\",testDF,inputCols)\n",
    "print(f\"RMSE is {evaluationMetrics[0]:.1f}\")\n",
    "print(f\"R^2 is {evaluationMetrics[1]:.5f}\")\n",
    "print(f\"Adjusted R^2 is {evaluationMetrics[2]:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The cross-validation does not change our results. It did select different parameters than the default, but the performance remains the same. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DS 5110 Spark 3.1",
   "language": "python",
   "name": "ds5110_spark3.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
