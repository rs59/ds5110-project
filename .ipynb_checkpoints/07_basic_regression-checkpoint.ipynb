{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File 07 - Basic Regression\n",
    "\n",
    "In this file, we create a small ML pipeline based on the output from File 03 (Basic Preprocessed Output).\n",
    "The files needed are `/processed_data/train_output.parquet` and `/processed_data/test_output.parquet`.\n",
    "\n",
    "The goal of this file is to provide:\n",
    "- The type of model\n",
    "- Best hyperparameters used\n",
    "- Size of the saved model\n",
    "- Performance metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up Spark session\n",
    "\n",
    "We can specify more options in the SparkSession creator, but currently the options are at the default settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 463 ms, sys: 393 ms, total: 856 ms\n",
      "Wall time: 5.19 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import types as T\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.functions import log\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "        .appName(\"project\") \\\n",
    "        .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in dataframes for train and test sets\n",
    "\n",
    "This data should have been previously generated: we can find it in the `processed_data` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------+--------------+---------------+------------------+----------------+\n",
      "|  user_id|m2_total_spend|m1_total_spend|m1_total_events|m1_purchase_events|m1_user_sessions|\n",
      "+---------+--------------+--------------+---------------+------------------+----------------+\n",
      "|216064734|           0.0|           0.0|              7|                 0|               3|\n",
      "|276954781|           0.0|           0.0|              1|                 0|               1|\n",
      "|300004940|           0.0|           0.0|             91|                 0|              15|\n",
      "|308982710|           0.0|           0.0|              7|                 0|               6|\n",
      "|324078599|           0.0|           0.0|              5|                 0|               3|\n",
      "+---------+--------------+--------------+---------------+------------------+----------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "CPU times: user 2.76 ms, sys: 1.86 ms, total: 4.62 ms\n",
      "Wall time: 4.43 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "trainDF = spark.read.parquet(\"./processed_data/train_output.parquet\")\n",
    "testDF = spark.read.parquet(\"./processed_data/test_output.parquet\")\n",
    "trainDF.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up Spark ML pipeline training for linear regression\n",
    "\n",
    "Here we decide which input columns should be used in order to create our training pipeline. To implement this step, we create the function `generatePipeline(inputCols, outputCol, trainDF)`. Then, we train the pipeline using this function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.14 ms, sys: 4.03 ms, total: 13.2 ms\n",
      "Wall time: 5.49 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "inputCols = [\"m1_total_spend\",\"m1_total_events\",\"m1_purchase_events\",\"m1_user_sessions\"]\n",
    "\n",
    "def generatePipeline(inputCols, outputCol):\n",
    "    # Select input columns for linear regression\n",
    "    vecAssembler = VectorAssembler(inputCols=inputCols, outputCol=\"features\")\n",
    "\n",
    "    # Select output column for linear regression\n",
    "    lr = LinearRegression(featuresCol=\"features\", labelCol=outputCol)\n",
    "\n",
    "    # The following lines (pipeline creation and fitting) replace these two commented-out lines.\n",
    "    # vecTrainDF = vecAssembler.transform(trainDF)\n",
    " \n",
    "    pipeline = Pipeline(stages=[vecAssembler, lr])\n",
    "    return pipeline\n",
    "    \n",
    "pipeline = generatePipeline(inputCols, \"m2_total_spend\")\n",
    "pipelineModel = pipeline.fit(trainDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View the model information\n",
    "\n",
    "Print out the model coefficients and view the RMSE and R^2. We define the functions `modelInfo(inputCols, pipelineModel)` and `getEvaluationMetrics(pipelineModel,outputCol,testDF)` to report this information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model coefficients\n",
      "          Column name  Coefficient\n",
      "0           intercept -2881.958103\n",
      "1      m1_total_spend     5.285700\n",
      "2     m1_total_events   313.911430\n",
      "3  m1_purchase_events -1679.682063\n",
      "4    m1_user_sessions  -248.626789\n"
     ]
    }
   ],
   "source": [
    "def modelInfo(inputCols, pipelineModel):\n",
    "    # Create a zipped list containing the coefficients and the data\n",
    "    modelCols = copy.deepcopy(inputCols)\n",
    "    modelCoeffs = list(pipelineModel.stages[-1].coefficients)\n",
    "    modelCoeffs.insert(0,pipelineModel.stages[-1].intercept)\n",
    "    modelCols.insert(0,\"intercept\")\n",
    "    modelZippedList = list(map(list, zip(modelCols, modelCoeffs)))\n",
    "\n",
    "    # Create the pandas DataFrame\n",
    "    modelDF = pd.DataFrame(modelZippedList, columns = ['Column name', 'Coefficient'])\n",
    "    return modelDF\n",
    "\n",
    "print(\"Model coefficients\")\n",
    "print(modelInfo(inputCols, pipelineModel))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-------------------+\n",
      "|m2_total_spend|         prediction|\n",
      "+--------------+-------------------+\n",
      "|           0.0|  950.2636956517554|\n",
      "|           0.0|  6979.865502618586|\n",
      "|           0.0|-1809.6545312152025|\n",
      "|           0.0| -2751.388820554537|\n",
      "|           0.0|  11623.25230816421|\n",
      "|           0.0| 2479.5597553504995|\n",
      "|           0.0| -2751.388820554537|\n",
      "|           0.0| 14852.674799063938|\n",
      "|           0.0|-2620.8195382524455|\n",
      "|           0.0|-2816.6734617055827|\n",
      "+--------------+-------------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "RMSE is 107094.8\n",
      "R^2 is 0.91824\n"
     ]
    }
   ],
   "source": [
    "def getEvaluationMetrics(pipelineModel,outputCol,testDF):\n",
    "    predDF = pipelineModel.transform(testDF)\n",
    "    predDF.select(outputCol, \"prediction\").show(10)\n",
    "\n",
    "    regressionEvaluator = RegressionEvaluator(\n",
    "    predictionCol=\"prediction\",\n",
    "    labelCol=outputCol,\n",
    "    metricName=\"rmse\")\n",
    "    rmse = regressionEvaluator.evaluate(predDF)\n",
    "\n",
    "    regressionEvaluator = RegressionEvaluator(\n",
    "    predictionCol=\"prediction\",\n",
    "    labelCol=outputCol,\n",
    "    metricName=\"r2\")\n",
    "    r2 = regressionEvaluator.evaluate(predDF)\n",
    "    \n",
    "    return rmse, r2\n",
    "\n",
    "evaluationMetrics = getEvaluationMetrics(pipelineModel,\"m2_total_spend\",testDF)\n",
    "print(f\"RMSE is {evaluationMetrics[0]:.1f}\")\n",
    "print(f\"R^2 is {evaluationMetrics[1]:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train linear regression model using log-transformed coefficients\n",
    "\n",
    "Now that we have used our new functions to test out the model accuracy on untransformed features and untransformed output, let's retrain the linear regression model on transformed features and/or transformed output (log scale). First we create these new features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------+--------------+---------------+------------------+----------------+------------------+--------------------+----------------------+--------------------+------------------+\n",
      "|  user_id|m2_total_spend|m1_total_spend|m1_total_events|m1_purchase_events|m1_user_sessions|m1_total_spend_log| m1_total_events_log|m1_purchase_events_log|m1_user_sessions_log|m2_total_spend_log|\n",
      "+---------+--------------+--------------+---------------+------------------+----------------+------------------+--------------------+----------------------+--------------------+------------------+\n",
      "|216064734|           0.0|           0.0|              7|                 0|               3|-6.907755278982137|  1.9460529959950605|    -6.907755278982137|  1.0989455664582302|-6.907755278982137|\n",
      "|276954781|           0.0|           0.0|              1|                 0|               1|-6.907755278982137|9.995003330834232E-4|    -6.907755278982137|9.995003330834232E-4|-6.907755278982137|\n",
      "+---------+--------------+--------------+---------------+------------------+----------------+------------------+--------------------+----------------------+--------------------+------------------+\n",
      "only showing top 2 rows\n",
      "\n",
      "+---------+--------------+--------------+---------------+------------------+----------------+------------------+-------------------+----------------------+--------------------+------------------+\n",
      "|  user_id|m2_total_spend|m1_total_spend|m1_total_events|m1_purchase_events|m1_user_sessions|m1_total_spend_log|m1_total_events_log|m1_purchase_events_log|m1_user_sessions_log|m2_total_spend_log|\n",
      "+---------+--------------+--------------+---------------+------------------+----------------+------------------+-------------------+----------------------+--------------------+------------------+\n",
      "|273033488|           0.0|           0.0|             13|                 0|               1|-6.907755278982137| 2.5650262775800314|    -6.907755278982137|9.995003330834232E-4|-6.907755278982137|\n",
      "|341377361|           0.0|           0.0|             33|                 0|               2|-6.907755278982137| 3.4965378640376557|    -6.907755278982137|  0.6936470556015963|-6.907755278982137|\n",
      "+---------+--------------+--------------+---------------+------------------+----------------+------------------+-------------------+----------------------+--------------------+------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainDF = trainDF \\\n",
    "          .withColumn(\"m1_total_spend_log\", log(col(\"m1_total_spend\")+0.001)) \\\n",
    "          .withColumn(\"m1_total_events_log\", log(col(\"m1_total_events\")+0.001)) \\\n",
    "          .withColumn(\"m1_purchase_events_log\", log(col(\"m1_purchase_events\")+0.001)) \\\n",
    "          .withColumn(\"m1_user_sessions_log\", log(col(\"m1_user_sessions\")+0.001)) \\\n",
    "          .withColumn(\"m2_total_spend_log\", log(col(\"m2_total_spend\")+0.001))\n",
    "\n",
    "testDF = testDF \\\n",
    "          .withColumn(\"m1_total_spend_log\", log(col(\"m1_total_spend\")+0.001)) \\\n",
    "          .withColumn(\"m1_total_events_log\", log(col(\"m1_total_events\")+0.001)) \\\n",
    "          .withColumn(\"m1_purchase_events_log\", log(col(\"m1_purchase_events\")+0.001)) \\\n",
    "          .withColumn(\"m1_user_sessions_log\", log(col(\"m1_user_sessions\")+0.001)) \\\n",
    "          .withColumn(\"m2_total_spend_log\", log(col(\"m2_total_spend\")+0.001))\n",
    "\n",
    "trainDF.show(2)\n",
    "testDF.show(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test out different combinations of log-transformed features and outputs\n",
    "\n",
    "Here we test out three additional transformations of the dataset in order to evaluate the linear regression model performance.\n",
    "\n",
    "Total tested model formulations:\n",
    "1. Normal inputs, normal output: `RMSE is 107094.8, R^2 is 0.91824`\n",
    "2. Log-transformed inputs, normal output: `RMSE is 372221.8, R^2 is 0.01233`\n",
    "3. Log-transformed inputs, log-transformed output: `RMSE is 3.1, R^2 is 0.20218` (note: cannot be compared to non-log-transformed outputs)\n",
    "4. Normal inputs, log-transformed output: `RMSE is 3.5, R^2 is 0.01027` (note: cannot be compared to non-log-transformed outputs)\n",
    "5. Normal and log-transformed inputs, normal output: `RMSE is 106947.5, R^2 is 0.91846`\n",
    "\n",
    "Due to the larger R^2 and smaller RMSE, we would suggest adopting the last model. Although linear regression does not take hyperparameters as such, we have made the pre-training choice to log-transform features and include them as well. In the future, it would be useful to do a more in-depth feature selection (perhaps a stepwise feature selection), and use AIC to determine model complexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Log-transformed inputs, normal output **\n",
      "Model coefficients\n",
      "              Column name    Coefficient\n",
      "0               intercept  423132.734213\n",
      "1      m1_total_spend_log  -82482.258824\n",
      "2     m1_total_events_log   11326.038662\n",
      "3  m1_purchase_events_log  145541.653360\n",
      "4    m1_user_sessions_log   -7671.589245\n",
      "+--------------+-------------------+\n",
      "|m2_total_spend|         prediction|\n",
      "+--------------+-------------------+\n",
      "|           0.0| 16577.787751273194|\n",
      "|           0.0| 21814.416458436986|\n",
      "|           0.0| 443.31442810606677|\n",
      "|           0.0| -9931.233204243472|\n",
      "|           0.0| 31133.362531157385|\n",
      "|           0.0|   6326.17963634443|\n",
      "|           0.0| -9931.233204243472|\n",
      "|           0.0|  15922.40951142332|\n",
      "|           0.0| -7399.075163899048|\n",
      "|           0.0|-12462.478659115674|\n",
      "+--------------+-------------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "RMSE is 372221.8\n",
      "R^2 is 0.01233\n"
     ]
    }
   ],
   "source": [
    "print(\"** Log-transformed inputs, normal output **\")\n",
    "inputCols = [\"m1_total_spend_log\",\"m1_total_events_log\",\"m1_purchase_events_log\",\"m1_user_sessions_log\"]\n",
    "outputCol = \"m2_total_spend\"\n",
    "\n",
    "pipeline = generatePipeline(inputCols, outputCol)\n",
    "pipelineModel = pipeline.fit(trainDF)\n",
    "\n",
    "print(\"Model coefficients\")\n",
    "print(modelInfo(inputCols, pipelineModel))\n",
    "\n",
    "evaluationMetrics = getEvaluationMetrics(pipelineModel,outputCol,testDF)\n",
    "print(f\"RMSE is {evaluationMetrics[0]:.1f}\")\n",
    "print(f\"R^2 is {evaluationMetrics[1]:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Log-transformed inputs, log-transformed output **\n",
      "Model coefficients\n",
      "              Column name  Coefficient\n",
      "0               intercept     1.538954\n",
      "1      m1_total_spend_log    -1.322550\n",
      "2     m1_total_events_log     0.923090\n",
      "3  m1_purchase_events_log     2.600790\n",
      "4    m1_user_sessions_log    -0.668795\n",
      "+------------------+------------------+\n",
      "|m2_total_spend_log|        prediction|\n",
      "+------------------+------------------+\n",
      "|-6.907755278982137|-4.923735095132409|\n",
      "|-6.907755278982137|-4.527105440221794|\n",
      "|-6.907755278982137|-6.268883690890332|\n",
      "|-6.907755278982137|-7.114425553958757|\n",
      "|-6.907755278982137|-3.737432978301927|\n",
      "|-6.907755278982137|-5.859492201162338|\n",
      "|-6.907755278982137|-7.114425553958757|\n",
      "|-6.907755278982137|-5.085323561619605|\n",
      "|-6.907755278982137|-6.938225364445513|\n",
      "|-6.907755278982137|-7.290562241221904|\n",
      "+------------------+------------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "RMSE is 3.1\n",
      "R^2 is 0.20218\n"
     ]
    }
   ],
   "source": [
    "print(\"** Log-transformed inputs, log-transformed output **\")\n",
    "inputCols = [\"m1_total_spend_log\",\"m1_total_events_log\",\"m1_purchase_events_log\",\"m1_user_sessions_log\"]\n",
    "outputCol = \"m2_total_spend_log\"\n",
    "\n",
    "pipeline = generatePipeline(inputCols, outputCol)\n",
    "pipelineModel = pipeline.fit(trainDF)\n",
    "\n",
    "print(\"Model coefficients\")\n",
    "print(modelInfo(inputCols, pipelineModel))\n",
    "\n",
    "evaluationMetrics = getEvaluationMetrics(pipelineModel,outputCol,testDF)\n",
    "print(f\"RMSE is {evaluationMetrics[0]:.1f}\")\n",
    "print(f\"R^2 is {evaluationMetrics[1]:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Normal inputs, log-transformed output **\n",
      "Model coefficients\n",
      "          Column name  Coefficient\n",
      "0           intercept    -6.113765\n",
      "1      m1_total_spend     0.000002\n",
      "2     m1_total_events     0.000773\n",
      "3  m1_purchase_events    -0.003500\n",
      "4    m1_user_sessions     0.002602\n",
      "+------------------+-------------------+\n",
      "|m2_total_spend_log|         prediction|\n",
      "+------------------+-------------------+\n",
      "|-6.907755278982137| -6.101116067603466|\n",
      "|-6.907755278982137|-6.0830573477300405|\n",
      "|-6.907755278982137| -6.104696865948726|\n",
      "|-6.907755278982137| -6.107015385757871|\n",
      "|-6.907755278982137| -6.074839509766491|\n",
      "|-6.907755278982137| -6.068424698054745|\n",
      "|-6.907755278982137| -6.107015385757871|\n",
      "|-6.907755278982137| -6.031534418371512|\n",
      "|-6.907755278982137|-6.1002658635935205|\n",
      "|-6.907755278982137| -6.110390146840046|\n",
      "+------------------+-------------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "RMSE is 3.5\n",
      "R^2 is 0.01027\n"
     ]
    }
   ],
   "source": [
    "print(\"** Normal inputs, log-transformed output **\")\n",
    "inputCols = [\"m1_total_spend\",\"m1_total_events\",\"m1_purchase_events\",\"m1_user_sessions\"]\n",
    "outputCol = \"m2_total_spend_log\"\n",
    "\n",
    "pipeline = generatePipeline(inputCols, outputCol)\n",
    "pipelineModel = pipeline.fit(trainDF)\n",
    "\n",
    "print(\"Model coefficients\")\n",
    "print(modelInfo(inputCols, pipelineModel))\n",
    "\n",
    "evaluationMetrics = getEvaluationMetrics(pipelineModel,outputCol,testDF)\n",
    "print(f\"RMSE is {evaluationMetrics[0]:.1f}\")\n",
    "print(f\"R^2 is {evaluationMetrics[1]:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Normal and log-transformed inputs, normal output **\n",
      "Model coefficients\n",
      "              Column name   Coefficient\n",
      "0               intercept -16570.114363\n",
      "1          m1_total_spend      5.288267\n",
      "2         m1_total_events    315.512164\n",
      "3      m1_purchase_events  -1686.180334\n",
      "4        m1_user_sessions   -228.815114\n",
      "5      m1_total_spend_log   4125.214436\n",
      "6     m1_total_events_log  -3332.968078\n",
      "7  m1_purchase_events_log  -6892.338972\n",
      "8    m1_user_sessions_log   -729.879780\n",
      "+--------------+-------------------+\n",
      "|m2_total_spend|         prediction|\n",
      "+--------------+-------------------+\n",
      "|           0.0| -2132.532440776513|\n",
      "|           0.0|   338.647900184842|\n",
      "|           0.0|-2206.7153234176476|\n",
      "|           0.0|-100.28359720380467|\n",
      "|           0.0|  4311.541875639628|\n",
      "|           0.0| -4265.069252114428|\n",
      "|           0.0|-100.28359720380467|\n",
      "|           0.0|  4844.746269128675|\n",
      "|           0.0| -2742.025703185145|\n",
      "|           0.0| 2627.1409886582915|\n",
      "+--------------+-------------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "RMSE is 106947.5\n",
      "R^2 is 0.91846\n"
     ]
    }
   ],
   "source": [
    "print(\"** Normal and log-transformed inputs, normal output **\")\n",
    "inputCols = [\"m1_total_spend\",\"m1_total_events\",\"m1_purchase_events\",\"m1_user_sessions\",\n",
    "             \"m1_total_spend_log\",\"m1_total_events_log\",\"m1_purchase_events_log\",\"m1_user_sessions_log\"]\n",
    "outputCol = \"m2_total_spend\"\n",
    "\n",
    "pipeline = generatePipeline(inputCols, outputCol)\n",
    "pipelineModel = pipeline.fit(trainDF)\n",
    "    \n",
    "print(\"Model coefficients\")\n",
    "print(modelInfo(inputCols, pipelineModel))\n",
    "\n",
    "evaluationMetrics = getEvaluationMetrics(pipelineModel,\"m2_total_spend\",testDF)\n",
    "print(f\"RMSE is {evaluationMetrics[0]:.1f}\")\n",
    "print(f\"R^2 is {evaluationMetrics[1]:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test out different combinations of hyperparameters\n",
    "\n",
    "Here we test out 25 combinations of hyperparameters under cross validation.\n",
    "\n",
    "- Regularization parameters: [0, 0.01, 0.2, 1, 10]\n",
    "- Amount of LASSO-ness: [0, 0.25, 0.5, 0.75, 1]\n",
    "\n",
    "The results that we find are that a regularization of 0.2 is desirable with an amount of LASSO-ness of 1 (L1 regularization only). Given that the R^2 and RMSE are quite similar to the previous models (`RMSE is 106998.3, R^2 is 0.91839`), it's not sure whether this is legitmately an improvement.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Normal and log-transformed inputs, normal output **\n",
      "CPU times: user 2.44 s, sys: 815 ms, total: 3.26 s\n",
      "Wall time: 5min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(\"** Normal and log-transformed inputs, normal output **\")\n",
    "inputCols = [\"m1_total_spend\",\"m1_total_events\",\"m1_purchase_events\",\"m1_user_sessions\",\n",
    "             \"m1_total_spend_log\",\"m1_total_events_log\",\"m1_purchase_events_log\",\"m1_user_sessions_log\"]\n",
    "pipeline = generatePipeline(inputCols, \"m2_total_spend\")\n",
    "pipelineModel = pipeline.fit(trainDF)\n",
    "vecAssembler = VectorAssembler(inputCols=inputCols, outputCol=\"features\")\n",
    "\n",
    "# Select output column for linear regression\n",
    "lr = LinearRegression(featuresCol=\"features\", labelCol=\"m2_total_spend\")\n",
    "\n",
    "pipeline = Pipeline(stages=[vecAssembler, lr])\n",
    "    \n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(lr.regParam, [0, 0.01, 0.2, 1, 10]) \\\n",
    "    .addGrid(lr.elasticNetParam, [0, 0.25, 0.5, 0.75, 1]) \\\n",
    "    .build()\n",
    "\n",
    "crossval = CrossValidator(estimator=pipeline,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=RegressionEvaluator().setLabelCol(\"m2_total_spend\"),\n",
    "                          numFolds=4)\n",
    "\n",
    "# Run cross-validation, and choose the best set of parameters.\n",
    "cvModel = crossval.fit(trainDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model coefficients\n",
      "              Column name   Coefficient\n",
      "0               intercept -10920.001611\n",
      "1          m1_total_spend      5.290461\n",
      "2         m1_total_events    315.345439\n",
      "3      m1_purchase_events  -1686.488895\n",
      "4        m1_user_sessions   -228.595785\n",
      "5      m1_total_spend_log   2882.170527\n",
      "6     m1_total_events_log  -3411.894171\n",
      "7  m1_purchase_events_log  -4846.929282\n",
      "8    m1_user_sessions_log   -673.152098\n",
      "+--------------+-------------------+\n",
      "|m2_total_spend|         prediction|\n",
      "+--------------+-------------------+\n",
      "|           0.0|-2229.3050498460416|\n",
      "|           0.0|  204.5318315520326|\n",
      "|           0.0|-2187.2374375699965|\n",
      "|           0.0| -8.009957100601241|\n",
      "|           0.0|   4107.66931780401|\n",
      "|           0.0| -4282.908267246825|\n",
      "|           0.0| -8.009957100601241|\n",
      "|           0.0|  4754.234076957451|\n",
      "|           0.0|-2665.0280750342354|\n",
      "|           0.0|  2734.737700567528|\n",
      "+--------------+-------------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "RMSE is 106998.3\n",
      "R^2 is 0.91839\n",
      "\n",
      "{Param(parent='LinearRegression_b46ec46d57f0', name='regParam', doc='regularization parameter (>= 0).'): 0.2, Param(parent='LinearRegression_b46ec46d57f0', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 1.0}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best model coefficients\")\n",
    "print(modelInfo(inputCols, cvModel.bestModel))\n",
    "\n",
    "evaluationMetrics = getEvaluationMetrics(cvModel.bestModel,\"m2_total_spend\",testDF)\n",
    "print(f\"RMSE is {evaluationMetrics[0]:.1f}\")\n",
    "print(f\"R^2 is {evaluationMetrics[1]:.5f}\")\n",
    "\n",
    "print()\n",
    "print(cvModel.getEstimatorParamMaps()[np.argmax(cvModel.avgMetrics)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save pipeline model and get model size\n",
    "\n",
    "The model size is 13.9 kB, according to the file explorer in Linux."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelinePath = \"models/lr-pipeline-model\"\n",
    "cvModel.bestModel.write().overwrite().save(pipelinePath)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DS 5110 Spark 3.1",
   "language": "python",
   "name": "ds5110_spark3.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
