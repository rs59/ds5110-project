{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosted Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 531 ms, sys: 407 ms, total: 939 ms\n",
      "Wall time: 5.77 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import types as T\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import GBTRegressor\n",
    "from pyspark.mllib.util import MLUtils\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.functions import log\n",
    "from pyspark.ml.stat import Correlation\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "        .appName(\"project\") \\\n",
    "        .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in dataframes for train and test sets\n",
    "\n",
    "This data should have been previously generated: we can find it in the `processed_data` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------------+-----------------+------------+--------------+------------------+------------------+----------------------------+---------------------------+----------------------------+----------------------------+------------------------+------------------------+-------------------------+------------------------+-----------+---------------+-----------+----------------------+------------------+------------------+-------------------------+---------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|  user_id|     T_total_spend|      total_spend|total_events|total_sessions|avg_session_length| sd_session_length|avg_interactions_per_session|sd_interactions_per_session|max_interactions_per_session|purchase_pct_of_total_events|view_pct_of_total_events|cart_pct_of_total_events|avg_purchases_per_session|sd_purchases_per_session|cart_events|purchase_events|view_events|sessions_with_purchase|sessions_with_cart|sessions_with_view|pct_sessions_end_purchase|pct_sessions_end_cart|     pca_purchases10|     pca_purchases20|     pca_purchases50|    pca_purchases100|\n",
      "+---------+------------------+-----------------+------------+--------------+------------------+------------------+----------------------------+---------------------------+----------------------------+----------------------------+------------------------+------------------------+-------------------------+------------------------+-----------+---------------+-----------+----------------------+------------------+------------------+-------------------------+---------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|512424146|11270.879859924316|526.6399841308594|         288|             7| 260.7142857142857|262.34564622885983|           5.142857142857143|         2.4784787961282104|                           8|         0.08333333333333333|      0.7777777777777778|      0.1388888888888889|      0.42857142857142855|      0.5345224838248488|          5|              3|         28|                     3|                 4|                 7|      0.42857142857142855|  0.14285714285714285|[-0.0221225462344...|[-0.0221225462344...|[-0.0221225462344...|[-0.0221225462344...|\n",
      "|512440689|               0.0|640.9400024414062|         113|            16|           566.875| 711.0573230525557|                      7.0625|          6.060459278525569|                          17|        0.008849557522123894|      0.9734513274336283|    0.017699115044247787|                   0.0625|     0.24999999999999997|          2|              1|        110|                     1|                 1|                16|                   0.0625|                  0.0|[4.69075176148695...|[4.69075176148694...|[4.69075176148694...|[4.69075176148694...|\n",
      "|512467274| 1532.799949645996|39.90000057220459|          30|             6|39.166666666666664| 75.29785300170694|          1.6666666666666667|         1.2110601416389968|                           4|                         0.1|                     0.8|                     0.1|      0.16666666666666666|       0.408248290463863|          1|              1|          8|                     1|                 1|                 6|      0.16666666666666666|                  0.0|[-6.0647773396890...|[-6.0647773396890...|[-6.0647773396890...|[-6.0647773396890...|\n",
      "|512470083|               0.0|385.8500061035156|          16|             5|             101.0|  72.8800384193093|                         3.2|         1.3038404810405297|                           4|                      0.0625|                    0.75|                  0.1875|                      0.2|      0.4472135954999579|          3|              1|         12|                     1|                 3|                 5|                      0.2|                  0.4|[-0.0053959415183...|[-0.0053959415183...|[-0.0053959415183...|[-0.0053959415183...|\n",
      "|512474045|               0.0|370.6499938964844|          29|             6|237.16666666666666|229.47541625774787|           4.833333333333333|         2.7141603981096374|                           9|         0.06896551724137931|      0.8620689655172413|     0.06896551724137931|       0.3333333333333333|      0.5163977794943222|          2|              2|         25|                     2|                 2|                 6|       0.3333333333333333|                  0.0|[-1.9975955387030...|[-1.9975955387030...|[-1.9975955387030...|[-1.9975955387030...|\n",
      "+---------+------------------+-----------------+------------+--------------+------------------+------------------+----------------------------+---------------------------+----------------------------+----------------------------+------------------------+------------------------+-------------------------+------------------------+-----------+---------------+-----------+----------------------+------------------+------------------+-------------------------+---------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "CPU times: user 2.94 ms, sys: 2.95 ms, total: 5.89 ms\n",
      "Wall time: 5.19 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "trainDF = spark.read.parquet(\"./processed_data/train.parquet\")\n",
    "testDF = spark.read.parquet(\"./processed_data/test.parquet\")\n",
    "trainDF.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## What the heck, we've used these columns in our previous models, might as well see how they do here. \n",
    "\n",
    "trainDF = trainDF \\\n",
    "          .withColumn(\"total_spend_log\", log(col(\"total_spend\")+0.001)) \\\n",
    "          .withColumn(\"total_events_log\", log(col(\"total_events\")+0.001)) \\\n",
    "          .withColumn(\"purchase_events_log\", log(col(\"purchase_events\")+0.001)) \\\n",
    "          .withColumn(\"total_sessions_log\", log(col(\"total_sessions\")+0.001)) \\\n",
    "          .withColumn(\"T_total_spend_log\", log(col(\"T_total_spend\")+0.001))\n",
    "\n",
    "testDF = testDF \\\n",
    "          .withColumn(\"total_spend_log\", log(col(\"total_spend\")+0.001)) \\\n",
    "          .withColumn(\"total_events_log\", log(col(\"total_events\")+0.001)) \\\n",
    "          .withColumn(\"purchase_events_log\", log(col(\"purchase_events\")+0.001)) \\\n",
    "          .withColumn(\"total_sessions_log\", log(col(\"total_sessions\")+0.001)) \\\n",
    "          .withColumn(\"T_total_spend_log\", log(col(\"T_total_spend\")+0.001))\n",
    "\n",
    "#trainDF.show(2)\n",
    "#testDF.show(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up Spark ML pipeline training for random forest\n",
    "\n",
    "We create the function `generatePipeline(inputCols, outputCol)`, Then, we train the pipeline using this function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 2 µs, total: 4 µs\n",
      "Wall time: 7.15 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def generatePipeline(inputCols, outputCol):\n",
    "    \n",
    "    # Select input columns for random forest regression\n",
    "    vecAssembler = VectorAssembler(inputCols=inputCols, outputCol=\"features\")\n",
    "\n",
    "    # Select output column for random forest regression\n",
    "    gb = GBTRegressor(featuresCol=\"features\", labelCol=outputCol, seed = 42)#, numTrees=5, maxDepth=5)\n",
    "    \n",
    "    pipeline = Pipeline(stages=[vecAssembler, gb])\n",
    "    return pipeline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate adjusted r2 (https://towardsdatascience.com/machine-learning-linear-regression-using-pyspark-9d5d5c772b42)\n",
    "def adj_r2(r2, inputCols, testDF):\n",
    "    n = testDF.count()\n",
    "    p = len(inputCols)\n",
    "    adjusted_r2 = 1-(((1-r2)*(n-1))/(n-p-1))\n",
    "    return adjusted_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getEvaluationMetrics(pipelineMode,outputCol,testDF,inputCols):\n",
    "    predDF = pipelineModel.transform(testDF)\n",
    "    predDF.select(outputCol, \"prediction\").show(10)\n",
    "    \n",
    "    regressionEvaluator = RegressionEvaluator(\n",
    "    predictionCol=\"prediction\",\n",
    "    labelCol=outputCol,\n",
    "    metricName=\"rmse\")\n",
    "    rmse = regressionEvaluator.evaluate(predDF)\n",
    "\n",
    "    regressionEvaluator = RegressionEvaluator(\n",
    "    predictionCol=\"prediction\",\n",
    "    labelCol=outputCol,\n",
    "    metricName=\"r2\")\n",
    "    r2 = regressionEvaluator.evaluate(predDF)\n",
    "    \n",
    "    # Manually calculate Adjusted r2\n",
    "    adjusted_r2 = adj_r2(r2, inputCols, testDF)\n",
    "    \n",
    "    return rmse, r2, adjusted_r2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelInfo(inputCols, pipelineModel):\n",
    "    modelCols = pipelineModel.stages[-2].getInputCols()\n",
    "    \n",
    "    feature_importance = pipelineModel.stages[-1].featureImportances\n",
    "    \n",
    "    return pd.DataFrame(list(zip(modelCols, feature_importance)), columns = ['Column name', 'Importance']).sort_values(by=\"Importance\", ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** All normal inputs, normal output **\n",
      "                     Column name  Importance\n",
      "1                   total_events    0.410232\n",
      "0                    total_spend    0.165761\n",
      "7   purchase_pct_of_total_events    0.095895\n",
      "18         pct_sessions_end_cart    0.030591\n",
      "8       view_pct_of_total_events    0.030071\n",
      "14        sessions_with_purchase    0.028706\n",
      "11                   cart_events    0.027229\n",
      "4             avg_session_length    0.022188\n",
      "2                purchase_events    0.021341\n",
      "6   max_interactions_per_session    0.020568\n",
      "13                   view_events    0.020451\n",
      "15            sessions_with_cart    0.019382\n",
      "5   avg_interactions_per_session    0.017602\n",
      "19             sd_session_length    0.016792\n",
      "21      sd_purchases_per_session    0.016539\n",
      "10     avg_purchases_per_session    0.015044\n",
      "9       cart_pct_of_total_events    0.014014\n",
      "20   sd_interactions_per_session    0.012699\n",
      "17     pct_sessions_end_purchase    0.006809\n",
      "3                 total_sessions    0.004292\n",
      "16            sessions_with_view    0.003793\n",
      "12               purchase_events    0.000000\n",
      "+-----------------+------------------+\n",
      "|    T_total_spend|        prediction|\n",
      "+-----------------+------------------+\n",
      "|              0.0| 2320.855657699718|\n",
      "|              0.0|2665.9120756174734|\n",
      "|              0.0|2916.7201242777583|\n",
      "|              0.0| 594.8293090971885|\n",
      "|              0.0| 842.9998173758462|\n",
      "|              0.0| 594.8293090971885|\n",
      "|              0.0| 1262.822201352476|\n",
      "|              0.0| 2507.062336580088|\n",
      "|79118.00024795532| 265476.9740658401|\n",
      "|663.1999969482422|2664.4324179675787|\n",
      "+-----------------+------------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "RMSE is 48437.0\n",
      "R^2 is 0.52140\n",
      "Adjusted R^2 is 0.52125\n"
     ]
    }
   ],
   "source": [
    "print(\"** All normal inputs, normal output **\")\n",
    "inputCols = [\"total_spend\",\"total_events\",\"purchase_events\", \"total_sessions\", \"avg_session_length\", \"avg_interactions_per_session\", \"max_interactions_per_session\",\n",
    "             \"purchase_pct_of_total_events\", \"view_pct_of_total_events\", \"cart_pct_of_total_events\",\"avg_purchases_per_session\", \"cart_events\", \"purchase_events\",\n",
    "             \"view_events\", \"sessions_with_purchase\", \"sessions_with_cart\",\"sessions_with_view\", \"pct_sessions_end_purchase\", \"pct_sessions_end_cart\", 'sd_session_length', \n",
    "             'sd_interactions_per_session', 'sd_purchases_per_session']\n",
    "\n",
    "outputCol = \"T_total_spend\"\n",
    "\n",
    "pipeline = generatePipeline(inputCols, outputCol)\n",
    "pipelineModel = pipeline.fit(trainDF)\n",
    "\n",
    "print(modelInfo(inputCols, pipelineModel))\n",
    "\n",
    "evaluationMetrics = getEvaluationMetrics(pipelineModel,outputCol,testDF, inputCols)\n",
    "print(f\"RMSE is {evaluationMetrics[0]:.1f}\")\n",
    "print(f\"R^2 is {evaluationMetrics[1]:.5f}\")\n",
    "print(f\"Adjusted R^2 is {evaluationMetrics[2]:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** All normal inputs + log inputs (26 total), normal output **\n",
      "                     Column name  Importance\n",
      "1                   total_events    0.398364\n",
      "0                    total_spend    0.165765\n",
      "7   purchase_pct_of_total_events    0.096189\n",
      "8       view_pct_of_total_events    0.030199\n",
      "13        sessions_with_purchase    0.028707\n",
      "11                   cart_events    0.027228\n",
      "17         pct_sessions_end_cart    0.023283\n",
      "4             avg_session_length    0.022235\n",
      "2                purchase_events    0.021341\n",
      "9       cart_pct_of_total_events    0.021194\n",
      "12                   view_events    0.020450\n",
      "6   max_interactions_per_session    0.019676\n",
      "14            sessions_with_cart    0.019614\n",
      "5   avg_interactions_per_session    0.017555\n",
      "18             sd_session_length    0.016560\n",
      "20      sd_purchases_per_session    0.016539\n",
      "10     avg_purchases_per_session    0.015037\n",
      "19   sd_interactions_per_session    0.013591\n",
      "22              total_events_log    0.011577\n",
      "16     pct_sessions_end_purchase    0.006810\n",
      "3                 total_sessions    0.004856\n",
      "15            sessions_with_view    0.003229\n",
      "21               total_spend_log    0.000000\n",
      "23           purchase_events_log    0.000000\n",
      "24            total_sessions_log    0.000000\n",
      "+-----------------+------------------+\n",
      "|    T_total_spend|        prediction|\n",
      "+-----------------+------------------+\n",
      "|              0.0| 2320.831952834184|\n",
      "|              0.0|2666.1427015595723|\n",
      "|              0.0|2917.4678244725656|\n",
      "|              0.0| 594.8325499377756|\n",
      "|              0.0| 843.0030582164335|\n",
      "|              0.0| 594.8325499377756|\n",
      "|              0.0| 1262.794692000358|\n",
      "|              0.0|  2507.03779655329|\n",
      "|79118.00024795532| 265476.1396698904|\n",
      "|663.1999969482422|2664.4356588081655|\n",
      "+-----------------+------------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "RMSE is 48435.8\n",
      "R^2 is 0.52143\n",
      "Adjusted R^2 is 0.52125\n"
     ]
    }
   ],
   "source": [
    "print(\"** All normal inputs + log inputs (25 total), normal output **\")\n",
    "inputCols = [\"total_spend\",\"total_events\",\"purchase_events\", \"total_sessions\", \"avg_session_length\", \"avg_interactions_per_session\", \"max_interactions_per_session\",\n",
    "             \"purchase_pct_of_total_events\", \"view_pct_of_total_events\", \"cart_pct_of_total_events\",\"avg_purchases_per_session\", \"cart_events\", \n",
    "             \"view_events\", \"sessions_with_purchase\", \"sessions_with_cart\",\"sessions_with_view\", \"pct_sessions_end_purchase\", \"pct_sessions_end_cart\", 'sd_session_length', \n",
    "             'sd_interactions_per_session', 'sd_purchases_per_session', 'total_spend_log', 'total_events_log', 'purchase_events_log', 'total_sessions_log']\n",
    "\n",
    "outputCol = \"T_total_spend\"\n",
    "\n",
    "pipeline = generatePipeline(inputCols, outputCol)\n",
    "pipelineModel = pipeline.fit(trainDF)\n",
    "\n",
    "print(modelInfo(inputCols, pipelineModel))\n",
    "\n",
    "evaluationMetrics = getEvaluationMetrics(pipelineModel,outputCol,testDF, inputCols)\n",
    "print(f\"RMSE is {evaluationMetrics[0]:.1f}\")\n",
    "print(f\"R^2 is {evaluationMetrics[1]:.5f}\")\n",
    "print(f\"Adjusted R^2 is {evaluationMetrics[2]:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How interesting! Three of the four log values wound up with importances of 0. How does a log output work for this one?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** All normal inputs + log inputs (25 total), normal output **\n",
      "                     Column name  Importance\n",
      "1                   total_events    0.353249\n",
      "12                   view_events    0.291121\n",
      "0                    total_spend    0.161128\n",
      "11                   cart_events    0.073254\n",
      "22              total_events_log    0.030372\n",
      "2                purchase_events    0.025939\n",
      "8       view_pct_of_total_events    0.022107\n",
      "7   purchase_pct_of_total_events    0.011118\n",
      "4             avg_session_length    0.011114\n",
      "9       cart_pct_of_total_events    0.004055\n",
      "5   avg_interactions_per_session    0.003885\n",
      "6   max_interactions_per_session    0.002780\n",
      "10     avg_purchases_per_session    0.002257\n",
      "15            sessions_with_view    0.001686\n",
      "13        sessions_with_purchase    0.001406\n",
      "20      sd_purchases_per_session    0.001217\n",
      "3                 total_sessions    0.001124\n",
      "14            sessions_with_cart    0.000892\n",
      "18             sd_session_length    0.000713\n",
      "19   sd_interactions_per_session    0.000338\n",
      "21               total_spend_log    0.000130\n",
      "17         pct_sessions_end_cart    0.000073\n",
      "16     pct_sessions_end_purchase    0.000042\n",
      "23           purchase_events_log    0.000000\n",
      "24            total_sessions_log    0.000000\n",
      "+------------------+-------------------+\n",
      "| T_total_spend_log|         prediction|\n",
      "+------------------+-------------------+\n",
      "|-6.907755278982137|  -5.47383877004993|\n",
      "|-6.907755278982137| -5.153753013088241|\n",
      "|-6.907755278982137|-4.1618374735757815|\n",
      "|-6.907755278982137|-5.6368410859689835|\n",
      "|-6.907755278982137| -5.150363519578567|\n",
      "|-6.907755278982137| -5.459668834417272|\n",
      "|-6.907755278982137|-3.6810329996213333|\n",
      "|-6.907755278982137|  -5.44219637069934|\n",
      "|11.278695703691795| 11.872630920276297|\n",
      "|6.4970781070591626|  7.565960538696759|\n",
      "+------------------+-------------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "RMSE is 4.5\n",
      "R^2 is 0.59348\n",
      "Adjusted R^2 is 0.59333\n"
     ]
    }
   ],
   "source": [
    "print(\"** All normal inputs + log inputs (25 total), log output **\")\n",
    "inputCols = [\"total_spend\",\"total_events\",\"purchase_events\", \"total_sessions\", \"avg_session_length\", \"avg_interactions_per_session\", \"max_interactions_per_session\",\n",
    "             \"purchase_pct_of_total_events\", \"view_pct_of_total_events\", \"cart_pct_of_total_events\",\"avg_purchases_per_session\", \"cart_events\", \n",
    "             \"view_events\", \"sessions_with_purchase\", \"sessions_with_cart\",\"sessions_with_view\", \"pct_sessions_end_purchase\", \"pct_sessions_end_cart\", 'sd_session_length', \n",
    "             'sd_interactions_per_session', 'sd_purchases_per_session', 'total_spend_log', 'total_events_log', 'purchase_events_log', 'total_sessions_log']\n",
    "\n",
    "outputCol = \"T_total_spend_log\"\n",
    "\n",
    "pipeline = generatePipeline(inputCols, outputCol)\n",
    "pipelineModel = pipeline.fit(trainDF)\n",
    "\n",
    "print(modelInfo(inputCols, pipelineModel))\n",
    "\n",
    "evaluationMetrics = getEvaluationMetrics(pipelineModel,outputCol,testDF, inputCols)\n",
    "print(f\"RMSE is {evaluationMetrics[0]:.1f}\")\n",
    "print(f\"R^2 is {evaluationMetrics[1]:.5f}\")\n",
    "print(f\"Adjusted R^2 is {evaluationMetrics[2]:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dang! The log output actually worked significantly better this time. We'll use that for the remainder. Time for tuning..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Smaller model, log output **\n",
      "    Column name  Importance\n",
      "1  total_events    0.431924\n",
      "3   view_events    0.283415\n",
      "0   total_spend    0.181242\n",
      "2   cart_events    0.103418\n",
      "+------------------+------------------+\n",
      "| T_total_spend_log|        prediction|\n",
      "+------------------+------------------+\n",
      "|-6.907755278982137|-5.521857618476705|\n",
      "|-6.907755278982137|-5.277740003874514|\n",
      "|-6.907755278982137|-4.584288139916862|\n",
      "|-6.907755278982137|-5.846964864405892|\n",
      "|-6.907755278982137|-5.403275607729301|\n",
      "|-6.907755278982137|-5.625976333857803|\n",
      "|-6.907755278982137|-4.257682714735065|\n",
      "|-6.907755278982137|-5.500642569113173|\n",
      "|11.278695703691795|12.321049141058792|\n",
      "|6.4970781070591626| 8.320510336325208|\n",
      "+------------------+------------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "RMSE is 4.5\n",
      "R^2 is 0.60170\n",
      "Adjusted R^2 is 0.60167\n"
     ]
    }
   ],
   "source": [
    "print(\"** Smaller model, log output **\")\n",
    "inputCols = [\"total_spend\",\"total_events\",\"cart_events\", \"view_events\"]\n",
    "\n",
    "outputCol = \"T_total_spend_log\"\n",
    "\n",
    "pipeline = generatePipeline(inputCols, outputCol)\n",
    "pipelineModel = pipeline.fit(trainDF)\n",
    "\n",
    "print(modelInfo(inputCols, pipelineModel))\n",
    "\n",
    "evaluationMetrics = getEvaluationMetrics(pipelineModel,outputCol,testDF, inputCols)\n",
    "print(f\"RMSE is {evaluationMetrics[0]:.1f}\")\n",
    "print(f\"R^2 is {evaluationMetrics[1]:.5f}\")\n",
    "print(f\"Adjusted R^2 is {evaluationMetrics[2]:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The champion model with the best adjusted r-square (.60167) has only 4 input columns, and uses the log output. But is it using the best hyperparameters? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 23 ms, sys: 9.24 ms, total: 32.3 ms\n",
      "Wall time: 7.72 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "inputCols = [\"total_spend\",\"total_events\",\"cart_events\", \"view_events\"]\n",
    "\n",
    "outputCol = \"T_total_spend_log\"\n",
    "\n",
    "pipeline = generatePipeline(inputCols, outputCol)\n",
    "pipelineModel = pipeline.fit(trainDF)\n",
    "\n",
    "vecAssembler = VectorAssembler(inputCols=inputCols, outputCol=\"features\")\n",
    "\n",
    "gb = GBTRegressor(featuresCol=\"features\", labelCol=outputCol, seed = 42)\n",
    "\n",
    "pipeline = Pipeline(stages=[vecAssembler, gb])\n",
    "\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(gb.lossType, [\"squared\", \"absolute\"]) \\\n",
    "    .addGrid(gb.maxIter, [10, 20, 30]) \\\n",
    "    .addGrid(gb.maxDepth, [2, 5, 10]) \\\n",
    "    .addGrid(gb.stepSize, [.01, .05, .1, .2, .5]) \\\n",
    "    .addGrid(gb.featureSubsetStrategy, ['sqrt', 'log2', 'onethird']) \\\n",
    "    .build()\n",
    "\n",
    "crossval = CrossValidator(estimator=pipeline,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=RegressionEvaluator().setLabelCol(\"T_total_spend\"),\n",
    "                          numFolds=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "cvModel = crossval.fit(trainDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print()\n",
    "print(cvModel.getEstimatorParamMaps()[np.argmax(cvModel.avgMetrics)])\n",
    "\n",
    "evaluationMetrics = getEvaluationMetrics(cvModel.bestModel,\"T_total_spend\",testDF,inputCols)\n",
    "print(f\"RMSE is {evaluationMetrics[0]:.1f}\")\n",
    "print(f\"R^2 is {evaluationMetrics[1]:.5f}\")\n",
    "print(f\"Adjusted R^2 is {evaluationMetrics[2]:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DS 5110 Spark 3.1",
   "language": "python",
   "name": "ds5110_spark3.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
