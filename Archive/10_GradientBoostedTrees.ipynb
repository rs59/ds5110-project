{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DONT USE GET RID OF\n",
    "\n",
    "File 08 - Gradient Boosted Tree\n",
    "##### Group 12:\n",
    "\n",
    "##### Hannah Schmuckler, mmc4cv\n",
    "\n",
    "##### Rob Schwartz, res7cd\n",
    "\n",
    "In this file, we create an ML pipeline based on the output from File 02 (Feature creation).\n",
    "\n",
    "The files needed are `/processed_data/train.parquet` and `/processed_data/test.parquet`.\n",
    "\n",
    "We create a gradient boosted tree model and fine-tune. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 658 ms, sys: 439 ms, total: 1.1 s\n",
      "Wall time: 8.47 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import types as T\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import GBTRegressor\n",
    "from pyspark.mllib.util import MLUtils\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.functions import log\n",
    "from pyspark.ml.stat import Correlation\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "        .appName(\"project\") \\\n",
    "        .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in dataframes for train and test sets\n",
    "\n",
    "This data should have been previously generated: we can find it in the `processed_data` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.25 ms, sys: 2.03 ms, total: 5.27 ms\n",
      "Wall time: 4.49 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "trainDF = spark.read.parquet(\"./processed_data/train.parquet\")\n",
    "testDF = spark.read.parquet(\"./processed_data/test.parquet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up Spark ML pipeline training for random forest\n",
    "\n",
    "We create the function `generatePipeline(inputCols, outputCol)`, Then, we train the pipeline using this function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8 µs, sys: 7 µs, total: 15 µs\n",
      "Wall time: 18.6 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def generatePipeline(inputCols, outputCol):\n",
    "    \n",
    "    # Select input columns for random forest regression\n",
    "    vecAssembler = VectorAssembler(inputCols=inputCols, outputCol=\"features\")\n",
    "\n",
    "    # Select output column for random forest regression\n",
    "    gb = GBTRegressor(featuresCol=\"features\", labelCol=outputCol, seed = 42)#, numTrees=5, maxDepth=5)\n",
    "    \n",
    "    pipeline = Pipeline(stages=[vecAssembler, gb])\n",
    "    return pipeline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate adjusted r2 (https://towardsdatascience.com/machine-learning-linear-regression-using-pyspark-9d5d5c772b42)\n",
    "def adj_r2(r2, inputCols, testDF):\n",
    "    n = testDF.count()\n",
    "    p = len(inputCols)\n",
    "    adjusted_r2 = 1-(((1-r2)*(n-1))/(n-p-1))\n",
    "    return adjusted_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getEvaluationMetrics(pipelineMode,outputCol,testDF,inputCols):\n",
    "    predDF = pipelineModel.transform(testDF)\n",
    "    predDF.select(outputCol, \"prediction\").show(10)\n",
    "    \n",
    "    regressionEvaluator = RegressionEvaluator(\n",
    "    predictionCol=\"prediction\",\n",
    "    labelCol=outputCol,\n",
    "    metricName=\"rmse\")\n",
    "    rmse = regressionEvaluator.evaluate(predDF)\n",
    "\n",
    "    regressionEvaluator = RegressionEvaluator(\n",
    "    predictionCol=\"prediction\",\n",
    "    labelCol=outputCol,\n",
    "    metricName=\"r2\")\n",
    "    r2 = regressionEvaluator.evaluate(predDF)\n",
    "    \n",
    "    # Manually calculate Adjusted r2\n",
    "    adjusted_r2 = adj_r2(r2, inputCols, testDF)\n",
    "    \n",
    "    return rmse, r2, adjusted_r2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelInfo(inputCols, pipelineModel):\n",
    "    modelCols = pipelineModel.stages[-2].getInputCols()\n",
    "    \n",
    "    feature_importance = pipelineModel.stages[-1].featureImportances\n",
    "    \n",
    "    return pd.DataFrame(list(zip(modelCols, feature_importance)), columns = ['Column name', 'Importance']).sort_values(by=\"Importance\", ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** All inputs, normal output **\n",
      "                     Column name  Importance\n",
      "15        sessions_with_purchase    0.149377\n",
      "0                    total_spend    0.120364\n",
      "19         pct_sessions_end_cart    0.107172\n",
      "7   max_interactions_per_session    0.072532\n",
      "5   avg_interactions_per_session    0.067686\n",
      "8   purchase_pct_of_total_events    0.061044\n",
      "3             avg_session_length    0.060804\n",
      "18     pct_sessions_end_purchase    0.051655\n",
      "10      cart_pct_of_total_events    0.051229\n",
      "6    sd_interactions_per_session    0.046800\n",
      "16            sessions_with_cart    0.046030\n",
      "9       view_pct_of_total_events    0.037471\n",
      "2                 total_sessions    0.033459\n",
      "11     avg_purchases_per_session    0.023684\n",
      "13                   cart_events    0.018355\n",
      "12      sd_purchases_per_session    0.014163\n",
      "14               purchase_events    0.012375\n",
      "1                   total_events    0.012209\n",
      "17            sessions_with_view    0.006955\n",
      "4              sd_session_length    0.006636\n",
      "+------------------+------------------+\n",
      "|     T_total_spend|        prediction|\n",
      "+------------------+------------------+\n",
      "|               0.0| 72.35716684143844|\n",
      "|               0.0|106.13102038049507|\n",
      "|               0.0| 135.9565603066918|\n",
      "|               0.0|104.81781940337372|\n",
      "|               0.0| 294.6448913093745|\n",
      "|               0.0|223.91730780483982|\n",
      "| 312.4200134277344|184.02941796547893|\n",
      "|  6009.78010559082| 708.7508791633687|\n",
      "|1627.1900024414062|199.44703484686946|\n",
      "|1393.8800354003906|209.50080678974197|\n",
      "+------------------+------------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "RMSE is 2410.8\n",
      "R^2 is 0.04282\n",
      "Adjusted R^2 is 0.04255\n"
     ]
    }
   ],
   "source": [
    "print(\"** All inputs, normal output **\")\n",
    "inputCols = [\"total_spend\", \"total_events\", \"total_sessions\", \"avg_session_length\", \"sd_session_length\", \"avg_interactions_per_session\", \n",
    "             \"sd_interactions_per_session\", \"max_interactions_per_session\", \"purchase_pct_of_total_events\", \"view_pct_of_total_events\",\n",
    "             \"cart_pct_of_total_events\", \"avg_purchases_per_session\", \"sd_purchases_per_session\", \"cart_events\", \"purchase_events\", \n",
    "             \"sessions_with_purchase\", \"sessions_with_cart\", \"sessions_with_view\", \"pct_sessions_end_purchase\", \n",
    "             \"pct_sessions_end_cart\"]\n",
    "outputCol = \"T_total_spend\"\n",
    "\n",
    "pipeline = generatePipeline(inputCols, outputCol)\n",
    "pipelineModel = pipeline.fit(trainDF)\n",
    "\n",
    "print(modelInfo(inputCols, pipelineModel))\n",
    "\n",
    "evaluationMetrics = getEvaluationMetrics(pipelineModel,outputCol,testDF, inputCols)\n",
    "print(f\"RMSE is {evaluationMetrics[0]:.1f}\")\n",
    "print(f\"R^2 is {evaluationMetrics[1]:.5f}\")\n",
    "print(f\"Adjusted R^2 is {evaluationMetrics[2]:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 23 ms, sys: 4.32 ms, total: 27.3 ms\n",
      "Wall time: 7.18 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "inputCols = [\"total_spend\",\"total_events\",\"cart_events\", \"view_events\"]\n",
    "\n",
    "outputCol = \"T_total_spend_log\"\n",
    "\n",
    "pipeline = generatePipeline(inputCols, outputCol)\n",
    "pipelineModel = pipeline.fit(trainDF)\n",
    "\n",
    "vecAssembler = VectorAssembler(inputCols=inputCols, outputCol=\"features\")\n",
    "\n",
    "gb = GBTRegressor(featuresCol=\"features\", labelCol=outputCol, seed = 42)\n",
    "\n",
    "pipeline = Pipeline(stages=[vecAssembler, gb])\n",
    "\n",
    "# Set parameters to test\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(gb.maxIter, [10, 20, 30]) \\\n",
    "    .addGrid(gb.stepSize, [.01, .1, .5]) \\\n",
    "    .build()\n",
    "\n",
    "crossval = CrossValidator(estimator=pipeline,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=RegressionEvaluator().setLabelCol(\"T_total_spend_log\"),\n",
    "                          numFolds=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.08 s, sys: 610 ms, total: 2.69 s\n",
      "Wall time: 5min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cvModel = crossval.fit(trainDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{Param(parent='GBTRegressor_d3ddeb2a7ab6', name='maxIter', doc='max number of iterations (>= 0).'): 10, Param(parent='GBTRegressor_d3ddeb2a7ab6', name='stepSize', doc='Step size (a.k.a. learning rate) in interval (0, 1] for shrinking the contribution of each estimator.'): 0.01}\n",
      "+-----------------+------------------+\n",
      "|    T_total_spend|        prediction|\n",
      "+-----------------+------------------+\n",
      "|              0.0|-5.401702215435658|\n",
      "|              0.0|-5.116493226972563|\n",
      "|              0.0|-4.613897781605019|\n",
      "|              0.0|-5.756182796571637|\n",
      "|              0.0|-5.572453561657388|\n",
      "|              0.0|-5.736000545638466|\n",
      "|              0.0|-5.182997024887596|\n",
      "|              0.0|-5.402200848194742|\n",
      "|79118.00024795532|11.953560429151835|\n",
      "|663.1999969482422| 8.014701964359105|\n",
      "+-----------------+------------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "RMSE is 71326.9\n",
      "R^2 is -0.03782\n",
      "Adjusted R^2 is -0.03788\n"
     ]
    }
   ],
   "source": [
    "print()\n",
    "print(cvModel.getEstimatorParamMaps()[np.argmax(cvModel.avgMetrics)])\n",
    "\n",
    "evaluationMetrics = getEvaluationMetrics(cvModel.bestModel,\"T_total_spend\",testDF,inputCols)\n",
    "print(f\"RMSE is {evaluationMetrics[0]:.1f}\")\n",
    "print(f\"R^2 is {evaluationMetrics[1]:.5f}\")\n",
    "print(f\"Adjusted R^2 is {evaluationMetrics[2]:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For some reason, doing cross validation/parameter tuning doesn't work at all on the gradient boosted tree. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DS 5110 Spark 3.1",
   "language": "python",
   "name": "ds5110_spark3.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
