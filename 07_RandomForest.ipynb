{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File 07 - Random Forest\n",
    "\n",
    "##### Group 12:\n",
    "\n",
    "##### Hannah Schmuckler, mmc4cv\n",
    "\n",
    "##### Rob Schwartz, res7cd\n",
    "\n",
    "In this file, we create an ML pipeline based on the output from File 02 (Feature creation).\n",
    "\n",
    "The files needed are `/processed_data/train.parquet` and `/processed_data/test.parquet`.\n",
    "\n",
    "We create a random forest model and fine-tune. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up Spark session\n",
    "\n",
    "We can specify more options in the SparkSession creator, but currently the options are at the default settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 513 ms, sys: 415 ms, total: 928 ms\n",
      "Wall time: 5.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import types as T\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "from pyspark.mllib.util import MLUtils\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.functions import log\n",
    "from pyspark.ml.stat import Correlation\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "        .appName(\"project\") \\\n",
    "        .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in dataframes for train and test sets\n",
    "\n",
    "This data should have been previously generated: we can find it in the `processed_data` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.87 ms, sys: 2.88 ms, total: 4.75 ms\n",
      "Wall time: 3.14 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "trainDF = spark.read.parquet(\"./processed_data/train.parquet\")\n",
    "testDF = spark.read.parquet(\"./processed_data/test.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up Spark ML pipeline training for random forest\n",
    "\n",
    "We create the function `generatePipeline(inputCols, outputCol)`, Then, we train the pipeline using this function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 2 µs, total: 4 µs\n",
      "Wall time: 6.91 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def generatePipeline(inputCols, outputCol):\n",
    "    \n",
    "    # Select input columns for random forest regression\n",
    "    vecAssembler = VectorAssembler(inputCols=inputCols, outputCol=\"features\")\n",
    "\n",
    "    # Select output column for random forest regression\n",
    "    rf = RandomForestRegressor(featuresCol=\"features\", labelCol=outputCol, seed = 42)#, numTrees=5, maxDepth=5)\n",
    "    \n",
    "    pipeline = Pipeline(stages=[vecAssembler, rf])\n",
    "    return pipeline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate adjusted r2 (https://towardsdatascience.com/machine-learning-linear-regression-using-pyspark-9d5d5c772b42)\n",
    "def adj_r2(r2, inputCols, testDF):\n",
    "    n = testDF.count()\n",
    "    p = len(inputCols)\n",
    "    adjusted_r2 = 1-(((1-r2)*(n-1))/(n-p-1))\n",
    "    return adjusted_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getEvaluationMetrics(pipelineMode,outputCol,testDF,inputCols):\n",
    "    predDF = pipelineModel.transform(testDF)\n",
    "    predDF.select(outputCol, \"prediction\").show(10)\n",
    "    \n",
    "    regressionEvaluator = RegressionEvaluator(\n",
    "    predictionCol=\"prediction\",\n",
    "    labelCol=outputCol,\n",
    "    metricName=\"rmse\")\n",
    "    rmse = regressionEvaluator.evaluate(predDF)\n",
    "\n",
    "    regressionEvaluator = RegressionEvaluator(\n",
    "    predictionCol=\"prediction\",\n",
    "    labelCol=outputCol,\n",
    "    metricName=\"r2\")\n",
    "    r2 = regressionEvaluator.evaluate(predDF)\n",
    "    \n",
    "    # Manually calculate Adjusted r2\n",
    "    adjusted_r2 = adj_r2(r2, inputCols, testDF)\n",
    "    \n",
    "    return rmse, r2, adjusted_r2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelInfo(inputCols, pipelineModel):\n",
    "    modelCols = pipelineModel.stages[-2].getInputCols()\n",
    "    \n",
    "    feature_importance = pipelineModel.stages[-1].featureImportances\n",
    "    \n",
    "    return pd.DataFrame(list(zip(modelCols, feature_importance)), columns = ['Column name', 'Importance']).sort_values(by=\"Importance\", ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** All inputs + normal output **\n",
      "                     Column name  Importance\n",
      "20               total_spend_log    0.171475\n",
      "15        sessions_with_purchase    0.162734\n",
      "0                    total_spend    0.134540\n",
      "16            sessions_with_cart    0.088704\n",
      "10      cart_pct_of_total_events    0.052779\n",
      "22           purchase_events_log    0.044009\n",
      "3             avg_session_length    0.037823\n",
      "14               purchase_events    0.034736\n",
      "6    sd_interactions_per_session    0.030049\n",
      "13                   cart_events    0.029198\n",
      "9       view_pct_of_total_events    0.028643\n",
      "24        avg_session_length_log    0.028189\n",
      "19         pct_sessions_end_cart    0.026727\n",
      "4              sd_session_length    0.024929\n",
      "8   purchase_pct_of_total_events    0.022557\n",
      "5   avg_interactions_per_session    0.020685\n",
      "7   max_interactions_per_session    0.017503\n",
      "12      sd_purchases_per_session    0.014780\n",
      "2                 total_sessions    0.012836\n",
      "11     avg_purchases_per_session    0.007375\n",
      "23            total_sessions_log    0.005814\n",
      "18     pct_sessions_end_purchase    0.001626\n",
      "1                   total_events    0.001021\n",
      "21              total_events_log    0.000641\n",
      "17            sessions_with_view    0.000627\n",
      "+------------------+------------------+\n",
      "|     T_total_spend|        prediction|\n",
      "+------------------+------------------+\n",
      "|               0.0|123.69139502591138|\n",
      "|               0.0| 128.0925443342161|\n",
      "|               0.0|123.69139502591138|\n",
      "|               0.0|123.69139502591138|\n",
      "|               0.0|185.61167413336833|\n",
      "|               0.0|193.95004187284317|\n",
      "| 312.4200134277344|185.61167413336833|\n",
      "|  6009.78010559082|  555.000570418849|\n",
      "|1627.1900024414062|206.70057312523394|\n",
      "|1393.8800354003906|  166.374529820961|\n",
      "+------------------+------------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "RMSE is 2305.6\n",
      "R^2 is 0.12449\n",
      "Adjusted R^2 is 0.12418\n"
     ]
    }
   ],
   "source": [
    "print(\"** All inputs + normal output **\")\n",
    "inputCols = [\"total_spend\", \"total_events\", \"total_sessions\", \"avg_session_length\", \"sd_session_length\", \"avg_interactions_per_session\", \n",
    "             \"sd_interactions_per_session\", \"max_interactions_per_session\", \"purchase_pct_of_total_events\", \"view_pct_of_total_events\",\n",
    "             \"cart_pct_of_total_events\", \"avg_purchases_per_session\", \"sd_purchases_per_session\", \"cart_events\", \"purchase_events\", \n",
    "             \"sessions_with_purchase\", \"sessions_with_cart\", \"sessions_with_view\", \"pct_sessions_end_purchase\", \n",
    "             \"pct_sessions_end_cart\", \"total_spend_log\", \"total_events_log\", \"purchase_events_log\", \"total_sessions_log\",\n",
    "             \"avg_session_length_log\"]\n",
    "outputCol = \"T_total_spend\" #Performance is about .106 with log output. \n",
    "\n",
    "pipeline = generatePipeline(inputCols, outputCol)\n",
    "pipelineModel = pipeline.fit(trainDF)\n",
    "\n",
    "print(modelInfo(inputCols, pipelineModel))\n",
    "\n",
    "evaluationMetrics = getEvaluationMetrics(pipelineModel,outputCol,testDF, inputCols)\n",
    "print(f\"RMSE is {evaluationMetrics[0]:.1f}\")\n",
    "print(f\"R^2 is {evaluationMetrics[1]:.5f}\")\n",
    "print(f\"Adjusted R^2 is {evaluationMetrics[2]:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Champion features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Reduced inputs, normal output **\n",
      "                     Column name  Importance\n",
      "18               total_spend_log    0.144169\n",
      "0                    total_spend    0.132870\n",
      "14        sessions_with_purchase    0.126674\n",
      "15            sessions_with_cart    0.103955\n",
      "19           purchase_events_log    0.088216\n",
      "13               purchase_events    0.053811\n",
      "2             avg_session_length    0.046355\n",
      "7   purchase_pct_of_total_events    0.040926\n",
      "9       cart_pct_of_total_events    0.040770\n",
      "3              sd_session_length    0.035845\n",
      "21        avg_session_length_log    0.034031\n",
      "8       view_pct_of_total_events    0.027884\n",
      "4   avg_interactions_per_session    0.021731\n",
      "17         pct_sessions_end_cart    0.021007\n",
      "11      sd_purchases_per_session    0.014427\n",
      "6   max_interactions_per_session    0.012821\n",
      "5    sd_interactions_per_session    0.012192\n",
      "12                   cart_events    0.011661\n",
      "10     avg_purchases_per_session    0.009966\n",
      "20            total_sessions_log    0.008608\n",
      "1                 total_sessions    0.006489\n",
      "16     pct_sessions_end_purchase    0.005591\n",
      "+------------------+------------------+\n",
      "|     T_total_spend|        prediction|\n",
      "+------------------+------------------+\n",
      "|               0.0|127.89173601938296|\n",
      "|               0.0|127.89173601938296|\n",
      "|               0.0|124.70660639217192|\n",
      "|               0.0|127.89173601938296|\n",
      "|               0.0|151.38401430890366|\n",
      "|               0.0|212.72132697760395|\n",
      "| 312.4200134277344|152.77675932147747|\n",
      "|  6009.78010559082| 583.0896028513991|\n",
      "|1627.1900024414062|207.15441984551194|\n",
      "|1393.8800354003906|152.77675932147747|\n",
      "+------------------+------------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "RMSE is 2255.8\n",
      "R^2 is 0.16190\n",
      "Adjusted R^2 is 0.16165\n"
     ]
    }
   ],
   "source": [
    "print(\"** Reduced inputs, normal output **\")\n",
    "inputCols = [\"total_spend\", \"total_sessions\", \"avg_session_length\", \"sd_session_length\", \"avg_interactions_per_session\", \n",
    "             \"sd_interactions_per_session\", \"max_interactions_per_session\", \"purchase_pct_of_total_events\", \"view_pct_of_total_events\",\n",
    "             \"cart_pct_of_total_events\", \"avg_purchases_per_session\", \"sd_purchases_per_session\", \"cart_events\", \"purchase_events\", \n",
    "             \"sessions_with_purchase\", \"sessions_with_cart\", \"pct_sessions_end_purchase\", \n",
    "             \"pct_sessions_end_cart\", \"total_spend_log\", \"purchase_events_log\", \"total_sessions_log\",\n",
    "             \"avg_session_length_log\"]\n",
    "\n",
    "outputCol = \"T_total_spend\"\n",
    "\n",
    "pipeline = generatePipeline(inputCols, outputCol)\n",
    "pipelineModel = pipeline.fit(trainDF)\n",
    "\n",
    "print(modelInfo(inputCols, pipelineModel))\n",
    "\n",
    "evaluationMetrics = getEvaluationMetrics(pipelineModel,outputCol,testDF, inputCols)\n",
    "print(f\"RMSE is {evaluationMetrics[0]:.1f}\")\n",
    "print(f\"R^2 is {evaluationMetrics[1]:.5f}\")\n",
    "print(f\"Adjusted R^2 is {evaluationMetrics[2]:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test out different combinations of hyperparameters on best features model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 23.2 ms, sys: 4.25 ms, total: 27.5 ms\n",
      "Wall time: 2.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "inputCols = [\"total_spend\", \"total_sessions\", \"avg_session_length\", \"sd_session_length\", \"avg_interactions_per_session\", \n",
    "             \"sd_interactions_per_session\", \"max_interactions_per_session\", \"purchase_pct_of_total_events\", \"view_pct_of_total_events\",\n",
    "             \"cart_pct_of_total_events\", \"avg_purchases_per_session\", \"sd_purchases_per_session\", \"cart_events\", \"purchase_events\", \n",
    "             \"sessions_with_purchase\", \"sessions_with_cart\", \"pct_sessions_end_purchase\", \n",
    "             \"pct_sessions_end_cart\", \"total_spend_log\", \"purchase_events_log\", \"total_sessions_log\",\n",
    "             \"avg_session_length_log\"]\n",
    "\n",
    "outputCol = \"T_total_spend\"\n",
    "\n",
    "pipeline = generatePipeline(inputCols, outputCol)\n",
    "pipelineModel = pipeline.fit(trainDF)\n",
    "\n",
    "vecAssembler = VectorAssembler(inputCols=inputCols, outputCol=\"features\")\n",
    "\n",
    "rf = RandomForestRegressor(featuresCol=\"features\", labelCol=outputCol)\n",
    "\n",
    "pipeline = Pipeline(stages=[vecAssembler, rf])\n",
    "\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(rf.numTrees, [5, 10, 20]) \\\n",
    "    .addGrid(rf.maxDepth, [2, 4, 10]) \\\n",
    "    .addGrid(rf.featureSubsetStrategy, ['sqrt', 'log2', 'onethird']) \\\n",
    "    .build()\n",
    "\n",
    "crossval = CrossValidator(estimator=pipeline,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=RegressionEvaluator().setLabelCol(\"T_total_spend\"),\n",
    "                          numFolds=4)\n",
    "\n",
    "# Run cross-validation, and choose the best set of parameters.\n",
    "#cvModel = crossval.fit(trainDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.91 s, sys: 1.81 s, total: 8.72 s\n",
      "Wall time: 5min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cvModel = crossval.setParallelism(8).fit(trainDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{Param(parent='RandomForestRegressor_94d8fbe9cceb', name='numTrees', doc='Number of trees to train (>= 1).'): 5, Param(parent='RandomForestRegressor_94d8fbe9cceb', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 10, Param(parent='RandomForestRegressor_94d8fbe9cceb', name='featureSubsetStrategy', doc=\"The number of features to consider for splits at each tree node. Supported options: 'auto' (choose automatically for task: If numTrees == 1, set to 'all'. If numTrees > 1 (forest), set to 'sqrt' for classification and to 'onethird' for regression), 'all' (use all features), 'onethird' (use 1/3 of the features), 'sqrt' (use sqrt(number of features)), 'log2' (use log2(number of features)), 'n' (when n is in the range (0, 1.0], use n * number of features. When n is in the range (1, number of features), use n features). default = 'auto'\"): 'onethird'}\n",
      "+------------------+------------------+\n",
      "|     T_total_spend|        prediction|\n",
      "+------------------+------------------+\n",
      "|               0.0|127.89173601938296|\n",
      "|               0.0|127.89173601938296|\n",
      "|               0.0|124.70660639217192|\n",
      "|               0.0|127.89173601938296|\n",
      "|               0.0|151.38401430890366|\n",
      "|               0.0|212.72132697760395|\n",
      "| 312.4200134277344|152.77675932147747|\n",
      "|  6009.78010559082| 583.0896028513991|\n",
      "|1627.1900024414062|207.15441984551194|\n",
      "|1393.8800354003906|152.77675932147747|\n",
      "+------------------+------------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "RMSE is 2255.8\n",
      "R^2 is 0.16190\n",
      "Adjusted R^2 is 0.16165\n"
     ]
    }
   ],
   "source": [
    "print()\n",
    "print(cvModel.getEstimatorParamMaps()[np.argmax(cvModel.avgMetrics)])\n",
    "\n",
    "evaluationMetrics = getEvaluationMetrics(cvModel.bestModel,\"T_total_spend\",testDF,inputCols)\n",
    "print(f\"RMSE is {evaluationMetrics[0]:.1f}\")\n",
    "print(f\"R^2 is {evaluationMetrics[1]:.5f}\")\n",
    "print(f\"Adjusted R^2 is {evaluationMetrics[2]:.5f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DS 5110 Spark 3.1",
   "language": "python",
   "name": "ds5110_spark3.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
