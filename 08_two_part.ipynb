{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File 08 - Two-part model (Logistic + Linear Regression)\n",
    "\n",
    "##### Group 12:\n",
    "\n",
    "##### Hannah Schmuckler, mmc4cv\n",
    "\n",
    "##### Rob Schwartz, res7cd\n",
    "\n",
    "In this file, we create a small ML pipeline based on the output from File 02 (Feature creation).\n",
    "\n",
    "We create a two part model made up of a logistic and a linear regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up Spark session\n",
    "\n",
    "We can specify more options in the SparkSession creator, but currently the options are at the default settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 877 ms, sys: 672 ms, total: 1.55 s\n",
      "Wall time: 14.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import types as T\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import VectorAssembler, StandardScaler\n",
    "from pyspark.ml.regression import LinearRegression, LinearRegressionModel, LinearRegressionSummary\n",
    "from pyspark.ml.evaluation import RegressionEvaluator, BinaryClassificationEvaluator\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.functions import log\n",
    "from pyspark.ml.stat import Correlation\n",
    "from pyspark.sql.functions import when\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from handyspark import *\n",
    "from matplotlib import pyplot as plt\n",
    "from pyspark.mllib.evaluation import BinaryClassificationMetrics, MulticlassMetrics\n",
    "from pyspark.sql.types import IntegerType, DoubleType\n",
    "from pyspark.sql.functions import lit\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "        .appName(\"project\") \\\n",
    "        .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in dataframes for train and test sets\n",
    "\n",
    "This data should have been previously generated: we can find it in the `processed_data` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.9 ms, sys: 1.68 ms, total: 3.58 ms\n",
      "Wall time: 6.84 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "trainDF = spark.read.parquet(\"./processed_data/train.parquet\")\n",
    "testDF = spark.read.parquet(\"./processed_data/test.parquet\")\n",
    "# trainDF.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label trainDF with 0 if they did not spend in m2 and 1 if they did"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDF = trainDF.withColumn('logistic_T_total_spend', when(trainDF.T_total_spend == 0, 0)\n",
    "                                                       .otherwise(1))\n",
    "testDF = testDF.withColumn('logistic_T_total_spend', when(testDF.T_total_spend == 0, 0)\n",
    "                                                       .otherwise(1))\n",
    "\n",
    "trainDF = trainDF.withColumn('logistic_T_total_spend', col(\"logistic_T_total_spend\").cast(DoubleType()))\n",
    "testDF = testDF.withColumn('logistic_T_total_spend', col(\"logistic_T_total_spend\").cast(DoubleType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up Spark ML pipeline training for logistic regression\n",
    "\n",
    "Here we decide which input columns should be used in order to create our training pipeline. To implement this step, we create the function `generatePipeline(inputCols, outputCol)`. Then, we train the pipeline using this function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1e+03 ns, sys: 1e+03 ns, total: 2 µs\n",
      "Wall time: 5.01 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def generateLogisticPipeline(inputCols, outputCol, threshold):\n",
    "    # Select input columns for linear regression\n",
    "    vecAssembler = VectorAssembler(inputCols=inputCols, outputCol=\"unscaled_features\")\n",
    "    # Standard Scale\n",
    "    ss = StandardScaler(inputCol=\"unscaled_features\", outputCol=\"features\")\n",
    "    # Select output column for linear regression\n",
    "    logR = LogisticRegression(featuresCol=\"features\", labelCol=outputCol, rawPredictionCol = \"Logistic_Probabilities\", predictionCol = \"Logistic_Predictions\", threshold = threshold)\n",
    "\n",
    "    # The following lines (pipeline creation and fitting) replace these two commented-out lines.\n",
    "    # vecTrainDF = vecAssembler.transform(trainDF)\n",
    " \n",
    "    pipeline = Pipeline(stages=[vecAssembler, ss, logR])\n",
    "    return pipeline\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View the model information\n",
    "\n",
    "Create function to print out the model coefficients for the overall model, RMSE and R^2. We define the functions `modelInfo(inputCols, pipelineModel)` and `getEvaluationMetrics(pipelineModel,outputCol,testDF)` to report this information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelInfo(inputCols, pipelineModel):\n",
    "    # Create a zipped list containing the coefficients and the data\n",
    "    modelCols = copy.deepcopy(inputCols)\n",
    "    modelCoeffs = list(pipelineModel.stages[-1].coefficients)\n",
    "    modelCoeffs.insert(0,pipelineModel.stages[-1].intercept)\n",
    "    modelCols.insert(0,\"intercept\")\n",
    "    modelZippedList = list(map(list, zip(modelCols, modelCoeffs)))\n",
    "    \n",
    "    \n",
    "    # Create the pandas DataFrame\n",
    "    modelDF = pd.DataFrame(modelZippedList, columns = ['Column name', 'Coefficient'])\n",
    "    #modelDF['pValues'] = pvals\n",
    "    return modelDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate adjusted r2 (https://towardsdatascience.com/machine-learning-linear-regression-using-pyspark-9d5d5c772b42)\n",
    "# This function will allow us to calculate the adjusted r-square value when we do PCA later. The default r-square function does not take into account k. \n",
    "def adj_r2(r2, inputCols, testDF, k = 0):\n",
    "    n = testDF.count()\n",
    "    if k == 0:\n",
    "        p = len(inputCols)\n",
    "    else: \n",
    "        p = len(inputCols) + k - 1\n",
    "    \n",
    "    adjusted_r2 = 1-(((1-r2)*(n-1))/(n-p-1))\n",
    "    return adjusted_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://towardsdatascience.com/binary-classifier-evaluation-made-easy-with-handyspark-3b1e69c12b4f\n",
    "def getLogisticEvaluationMetrics(pipelineModel,outputCol,testDF,inputCols):\n",
    "    predDF = pipelineModel.transform(testDF)\n",
    "    preds_only = predDF.select(outputCol, \"Logistic_Predictions\")\n",
    "    preds_only.show(5)\n",
    "    \n",
    "    preds_only = preds_only.rdd\n",
    "    \n",
    "    metrics = MulticlassMetrics(preds_only)\n",
    "    print(metrics.confusionMatrix().toArray())\n",
    "    print(\"Accuracy: \" + str(metrics.accuracy))\n",
    "\n",
    "    return predDF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Column name  Coefficient\n",
      "0                      intercept    -1.087308\n",
      "1                    total_spend     0.027652\n",
      "2                   total_events     0.166859\n",
      "3                 total_sessions     1.422216\n",
      "4             avg_session_length    -0.089043\n",
      "5              sd_session_length     0.267300\n",
      "6   avg_interactions_per_session    -0.058958\n",
      "7    sd_interactions_per_session     0.025095\n",
      "8   max_interactions_per_session    -0.045492\n",
      "9   purchase_pct_of_total_events    -0.187097\n",
      "10      view_pct_of_total_events    -0.078184\n",
      "11      cart_pct_of_total_events    -0.095201\n",
      "12     avg_purchases_per_session    -0.129099\n",
      "13      sd_purchases_per_session     0.059970\n",
      "14                   cart_events    -0.049034\n",
      "15               purchase_events    -0.192963\n",
      "16        sessions_with_purchase     0.220615\n",
      "17            sessions_with_cart    -0.071309\n",
      "18            sessions_with_view    -1.529007\n",
      "19     pct_sessions_end_purchase     0.469537\n",
      "20         pct_sessions_end_cart     0.045707\n",
      "21               total_spend_log     0.037477\n",
      "22              total_events_log    -0.036898\n",
      "23           purchase_events_log     0.412189\n",
      "24            total_sessions_log     0.398391\n",
      "25        avg_session_length_log    -0.208165\n",
      "+----------------------+--------------------+\n",
      "|logistic_T_total_spend|Logistic_Predictions|\n",
      "+----------------------+--------------------+\n",
      "|                   0.0|                 0.0|\n",
      "|                   0.0|                 0.0|\n",
      "|                   0.0|                 0.0|\n",
      "|                   0.0|                 0.0|\n",
      "|                   0.0|                 1.0|\n",
      "+----------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "[[29121.  5872.]\n",
      " [24011. 12553.]]\n",
      "Accuracy: 0.5823888648210518\n",
      "CPU times: user 54.6 ms, sys: 19.7 ms, total: 74.3 ms\n",
      "Wall time: 35.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "inputCols = [\"total_spend\", \"total_events\", \"total_sessions\", \"avg_session_length\", \"sd_session_length\", \"avg_interactions_per_session\", \n",
    "             \"sd_interactions_per_session\", \"max_interactions_per_session\", \"purchase_pct_of_total_events\", \"view_pct_of_total_events\",\n",
    "             \"cart_pct_of_total_events\", \"avg_purchases_per_session\", \"sd_purchases_per_session\", \"cart_events\", \"purchase_events\", \n",
    "             \"sessions_with_purchase\", \"sessions_with_cart\", \"sessions_with_view\", \"pct_sessions_end_purchase\", \n",
    "             \"pct_sessions_end_cart\", \"total_spend_log\", \"total_events_log\", \"purchase_events_log\", \"total_sessions_log\",\n",
    "             \"avg_session_length_log\"]\n",
    "outputCol= \"logistic_T_total_spend\"\n",
    "\n",
    "pipeline = generateLogisticPipeline(inputCols, outputCol, .2) #Iterative testing determined that a threshold of .2 led to the highest overal adj R^2 for the model\n",
    "pipelineModel = pipeline.fit(trainDF)\n",
    "\n",
    "print(modelInfo(inputCols, pipelineModel))\n",
    "\n",
    "logistic_predictions = getLogisticEvaluationMetrics(pipelineModel,outputCol,testDF, inputCols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Threshold of .2 maximizes model adj-r^2, though it does not maximize the accuracy of this logistic regression. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Next, we'll train a linear regression model using only the true positive training data, and generate a regression prediction for all test data that had a prediction of positive. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "part_2_train = trainDF.filter(col(\"logistic_T_total_spend\") == 1)\n",
    "part_2_test = logistic_predictions.filter(col(\"Logistic_Predictions\") == 1).withColumnRenamed('probability', \"ProbabilityLogistic\")\n",
    "\n",
    "part_1_test = logistic_predictions.filter(col(\"Logistic_Predictions\") == 0).withColumnRenamed('probability', \"ProbabilityLogistic\") \\\n",
    "    .withColumn(\"\", lit(None)) ## For overall accuracy metrics later, will be joined with output of part_2_test's regression predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74751\n",
      "36564\n"
     ]
    }
   ],
   "source": [
    "print(part_2_train.count())\n",
    "print(part_2_test.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 20.5 ms, sys: 1.46 ms, total: 22 ms\n",
      "Wall time: 6.84 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def generateLinearPipeline(inputCols, outputCol):\n",
    "    # Select input columns for linear regression\n",
    "    vecAssembler = VectorAssembler(inputCols=inputCols, outputCol=\"unscaled_features2\")\n",
    "    # Standard Scale\n",
    "    ss = StandardScaler(inputCol=\"unscaled_features2\", outputCol=\"features2\")\n",
    "    # Select output column for linear regression\n",
    "    lr = LinearRegression(featuresCol=\"features2\", labelCol=outputCol)\n",
    "\n",
    "    # The following lines (pipeline creation and fitting) replace these two commented-out lines.\n",
    "    # vecTrainDF = vecAssembler.transform(trainDF)\n",
    " \n",
    "    pipeline = Pipeline(stages=[vecAssembler, ss, lr])\n",
    "    return pipeline\n",
    "    \n",
    "pipeline = generateLinearPipeline(inputCols, \"T_total_spend\")\n",
    "pipelineModel = pipeline.fit(trainDF)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLinearEvaluationMetrics(linearPipelineModel,outputCol,testDF,inputCols):\n",
    "    new_preds = pipelineModel.transform(testDF)\n",
    "    \n",
    "    # Merge the predictions from the linear regression with predictions from the logistic regression performed above. \n",
    "    # That will allow this to output complete results. \n",
    "    predDF = new_preds.unionByName(part_1_test, allowMissingColumns=True)\n",
    "\n",
    "    predDF = predDF.withColumn(\"FinalPredictions\", when(col(\"Logistic_Predictions\") == 0, 0.0)\n",
    "                               .otherwise(col(\"prediction\")))\n",
    "\n",
    "    predDF.select(outputCol, \"FinalPredictions\").show()\n",
    "    \n",
    "    regressionEvaluator = RegressionEvaluator(\n",
    "    predictionCol=\"FinalPredictions\",\n",
    "    labelCol=outputCol,\n",
    "    metricName=\"rmse\")\n",
    "    rmse = regressionEvaluator.evaluate(predDF)\n",
    "\n",
    "    regressionEvaluator = RegressionEvaluator(\n",
    "    predictionCol=\"FinalPredictions\",\n",
    "    labelCol=outputCol,\n",
    "    metricName=\"r2\")\n",
    "    r2 = regressionEvaluator.evaluate(predDF)\n",
    "      \n",
    "    # Manually calculate Adjusted r2\n",
    "    adjusted_r2 = adj_r2(r2, inputCols, predDF)\n",
    "    \n",
    "    return rmse, r2, adjusted_r2, predDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** All original inputs, original output **\n",
      "Model coefficients\n",
      "                     Column name  Coefficient\n",
      "0                      intercept   759.390549\n",
      "1                    total_spend  2149.124576\n",
      "2                   total_events   -48.135840\n",
      "3                purchase_events   303.019611\n",
      "4                 total_sessions  -789.070612\n",
      "5             avg_session_length   -29.179753\n",
      "6   avg_interactions_per_session   -65.282682\n",
      "7   max_interactions_per_session   115.651063\n",
      "8   purchase_pct_of_total_events    35.111501\n",
      "9       view_pct_of_total_events   -18.064595\n",
      "10      cart_pct_of_total_events     3.097761\n",
      "11     avg_purchases_per_session  -152.356488\n",
      "12                   cart_events    74.457028\n",
      "13                   view_events   -92.113428\n",
      "14        sessions_with_purchase  -907.340709\n",
      "15            sessions_with_cart   928.968113\n",
      "16            sessions_with_view   724.985263\n",
      "17     pct_sessions_end_purchase   142.424649\n",
      "18         pct_sessions_end_cart  -130.378715\n",
      "19             sd_session_length    41.602920\n",
      "20   sd_interactions_per_session   -70.781923\n",
      "21      sd_purchases_per_session   120.432828\n",
      "+------------------+------------------+\n",
      "|     T_total_spend|  FinalPredictions|\n",
      "+------------------+------------------+\n",
      "|               0.0| 624.7580396565033|\n",
      "|               0.0| 526.3177991687103|\n",
      "| 312.4200134277344| 557.3234942313471|\n",
      "|  6009.78010559082| 1652.212288595837|\n",
      "|1627.1900024414062| 854.8646853826301|\n",
      "| 573.9199829101562| 782.6884600712948|\n",
      "| 622.4000244140625|1788.7013687921294|\n",
      "|               0.0| 1296.743241190729|\n",
      "|6970.7298583984375| 1623.917173928868|\n",
      "|               0.0| 948.4589204267552|\n",
      "|               0.0| 953.9965023178005|\n",
      "|5785.0001220703125|1821.4951010726202|\n",
      "|1130.3900146484375| 990.4017375342486|\n",
      "|102.16000366210938|  1269.71019400308|\n",
      "| 339.6800079345703| 5593.528154880265|\n",
      "|               0.0|1108.6551393630693|\n",
      "| 463.3199920654297| 926.9081222885573|\n",
      "|               0.0|1752.9039383544161|\n",
      "|              69.5| 986.9951442716175|\n",
      "| 2151.820037841797| 701.1800346423735|\n",
      "+------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "RMSE is 2301.5\n",
      "R^2 is 0.12762\n",
      "Adjusted R^2 is 0.12736\n"
     ]
    }
   ],
   "source": [
    "print(\"** All original inputs, original output **\")\n",
    "inputCols = [\"total_spend\",\"total_events\",\"purchase_events\", \"total_sessions\", \"avg_session_length\", \"avg_interactions_per_session\", \"max_interactions_per_session\",\n",
    "             \"purchase_pct_of_total_events\", \"view_pct_of_total_events\", \"cart_pct_of_total_events\",\"avg_purchases_per_session\", \"cart_events\", \"view_events\", \n",
    "             \"sessions_with_purchase\", \"sessions_with_cart\",\"sessions_with_view\", \"pct_sessions_end_purchase\", \"pct_sessions_end_cart\", 'sd_session_length', \n",
    "             'sd_interactions_per_session', 'sd_purchases_per_session']\n",
    "\n",
    "\n",
    "outputCol = \"T_total_spend\"\n",
    "\n",
    "pipeline = generateLinearPipeline(inputCols, outputCol)\n",
    "pipelineModel = pipeline.fit(part_2_train)\n",
    "\n",
    "print(\"Model coefficients\")\n",
    "print(modelInfo(inputCols, pipelineModel))\n",
    "\n",
    "evaluationMetrics = getLinearEvaluationMetrics(pipelineModel,outputCol,part_2_test, inputCols)\n",
    "print(f\"RMSE is {evaluationMetrics[0]:.1f}\")\n",
    "print(f\"R^2 is {evaluationMetrics[1]:.5f}\")\n",
    "print(f\"Adjusted R^2 is {evaluationMetrics[2]:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Champion Model **\n",
      "CPU times: user 3.92 s, sys: 694 ms, total: 4.62 s\n",
      "Wall time: 1min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(\"** Champion Model **\")\n",
    "inputCols = [\"total_spend\",\"purchase_events\",\"avg_interactions_per_session\", \n",
    "             \"purchase_pct_of_total_events\",\"cart_events\", \"view_events\", \n",
    "             \"sessions_with_purchase\", \"sessions_with_cart\",\"pct_sessions_end_purchase\", \"pct_sessions_end_cart\",  \n",
    "             'sd_purchases_per_session']\n",
    "\n",
    "outputCol = \"T_total_spend\"\n",
    "# Below creation of pipeline is necessary for crossval to run.\n",
    "vecAssembler = VectorAssembler(inputCols=inputCols, outputCol=\"unscaled_features\")\n",
    "# Standard Scale\n",
    "ss = StandardScaler(inputCol=\"unscaled_features\", outputCol=\"features\")\n",
    "# Select output column for linear regression\n",
    "lr = LinearRegression(featuresCol=\"features\", labelCol=\"T_total_spend\")\n",
    "\n",
    "pipeline = Pipeline(stages=[vecAssembler,ss, lr])\n",
    "    \n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(lr.regParam, [0, 0.01, 0.2, 1, 10]) \\\n",
    "    .addGrid(lr.elasticNetParam, [0, 0.25, 0.5, 0.75, 1]) \\\n",
    "    .build()\n",
    "\n",
    "crossval = CrossValidator(estimator=pipeline,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=RegressionEvaluator().setLabelCol(\"T_total_spend\"),\n",
    "                          numFolds=4)\n",
    "\n",
    "# Run cross-validation, and choose the best set of parameters.\n",
    "cvModel = crossval.setParallelism(8).fit(part_2_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model coefficients\n",
      "                     Column name  Coefficient\n",
      "0                      intercept   722.584726\n",
      "1                    total_spend  2143.824564\n",
      "2                purchase_events   129.044353\n",
      "3   avg_interactions_per_session   -82.542527\n",
      "4   purchase_pct_of_total_events    26.390023\n",
      "5                    cart_events   151.070671\n",
      "6                    view_events   -62.329827\n",
      "7         sessions_with_purchase  -426.917763\n",
      "8             sessions_with_cart   456.417060\n",
      "9      pct_sessions_end_purchase    33.579882\n",
      "10         pct_sessions_end_cart   -56.555954\n",
      "11      sd_purchases_per_session    78.266746\n",
      "+------------------+------------------+\n",
      "|     T_total_spend|  FinalPredictions|\n",
      "+------------------+------------------+\n",
      "|               0.0| 624.7580396565033|\n",
      "|               0.0| 526.3177991687103|\n",
      "| 312.4200134277344| 557.3234942313471|\n",
      "|  6009.78010559082| 1652.212288595837|\n",
      "|1627.1900024414062| 854.8646853826301|\n",
      "| 573.9199829101562| 782.6884600712948|\n",
      "| 622.4000244140625|1788.7013687921294|\n",
      "|               0.0| 1296.743241190729|\n",
      "|6970.7298583984375| 1623.917173928868|\n",
      "|               0.0| 948.4589204267552|\n",
      "|               0.0| 953.9965023178005|\n",
      "|5785.0001220703125|1821.4951010726202|\n",
      "|1130.3900146484375| 990.4017375342486|\n",
      "|102.16000366210938|  1269.71019400308|\n",
      "| 339.6800079345703| 5593.528154880265|\n",
      "|               0.0|1108.6551393630693|\n",
      "| 463.3199920654297| 926.9081222885573|\n",
      "|               0.0|1752.9039383544161|\n",
      "|              69.5| 986.9951442716175|\n",
      "| 2151.820037841797| 701.1800346423735|\n",
      "+------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "RMSE is 2301.5\n",
      "R^2 is 0.12762\n",
      "Adjusted R^2 is 0.12748\n",
      "\n",
      "{Param(parent='LinearRegression_6b486286d00a', name='regParam', doc='regularization parameter (>= 0).'): 1.0, Param(parent='LinearRegression_6b486286d00a', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.75}\n",
      "\n",
      "[4189.06088627059, 4189.06088627059, 4189.06088627059, 4189.06088627059, 4189.06088627059, 4189.060424056675, 4189.08098648758, 4189.075699735012, 4189.0498262594065, 4189.015788630961, 4189.051647627239, 4189.037022263414, 4189.037344806703, 4189.0339055731065, 4189.047150598319, 4189.014811140469, 4189.017855114467, 4188.863703321923, 4189.851095051968, 4188.886089304155, 4188.612875248429, 4188.418438017293, 4188.364271623554, 4188.3663726461355, 4188.3910740575475]\n"
     ]
    }
   ],
   "source": [
    "print(\"Best model coefficients\")\n",
    "print(modelInfo(inputCols, cvModel.bestModel))\n",
    "\n",
    "\n",
    "evaluationMetrics = getLinearEvaluationMetrics(cvModel.bestModel,\"T_total_spend\",part_2_test,inputCols)\n",
    "print(f\"RMSE is {evaluationMetrics[0]:.1f}\")\n",
    "print(f\"R^2 is {evaluationMetrics[1]:.5f}\")\n",
    "print(f\"Adjusted R^2 is {evaluationMetrics[2]:.5f}\")\n",
    "\n",
    "print()\n",
    "print(cvModel.getEstimatorParamMaps()[np.argmax(cvModel.avgMetrics)])\n",
    "print()\n",
    "print(cvModel.avgMetrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DS 5110 Spark 3.1",
   "language": "python",
   "name": "ds5110_spark3.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
