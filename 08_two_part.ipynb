{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File 08 - Two-part model (Logistic + Linear Regression)\n",
    "\n",
    "##### Group 12:\n",
    "\n",
    "##### Hannah Schmuckler, mmc4cv\n",
    "\n",
    "##### Rob Schwartz, res7cd\n",
    "\n",
    "In this file, we create a small ML pipeline based on the output from File 02 (Feature creation).\n",
    "\n",
    "We create a two part model made up of a logistic and a linear regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up Spark session\n",
    "\n",
    "We can specify more options in the SparkSession creator, but currently the options are at the default settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 983 ms, sys: 714 ms, total: 1.7 s\n",
      "Wall time: 6.56 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import types as T\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import LinearRegression, LinearRegressionModel, LinearRegressionSummary\n",
    "from pyspark.ml.evaluation import RegressionEvaluator, BinaryClassificationEvaluator\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.functions import log\n",
    "from pyspark.ml.stat import Correlation\n",
    "from pyspark.sql.functions import when\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from handyspark import *\n",
    "from matplotlib import pyplot as plt\n",
    "from pyspark.mllib.evaluation import BinaryClassificationMetrics, MulticlassMetrics\n",
    "from pyspark.sql.types import IntegerType, DoubleType\n",
    "from pyspark.sql.functions import lit\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "        .appName(\"project\") \\\n",
    "        .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in dataframes for train and test sets\n",
    "\n",
    "This data should have been previously generated: we can find it in the `processed_data` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.08 ms, sys: 1.84 ms, total: 5.92 ms\n",
      "Wall time: 3.12 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "trainDF = spark.read.parquet(\"./processed_data/train.parquet\")\n",
    "testDF = spark.read.parquet(\"./processed_data/test.parquet\")\n",
    "# trainDF.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label trainDF with 0 if they did not spend in m2 and 1 if they did"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDF = trainDF.withColumn('logistic_T_total_spend', when(trainDF.T_total_spend == 0, 0)\n",
    "                                                       .otherwise(1))\n",
    "testDF = testDF.withColumn('logistic_T_total_spend', when(testDF.T_total_spend == 0, 0)\n",
    "                                                       .otherwise(1))\n",
    "\n",
    "trainDF = trainDF.withColumn('logistic_T_total_spend', col(\"logistic_T_total_spend\").cast(DoubleType()))\n",
    "testDF = testDF.withColumn('logistic_T_total_spend', col(\"logistic_T_total_spend\").cast(DoubleType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up Spark ML pipeline training for logistic regression\n",
    "\n",
    "Here we decide which input columns should be used in order to create our training pipeline. To implement this step, we create the function `generatePipeline(inputCols, outputCol)`. Then, we train the pipeline using this function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 µs, sys: 3 µs, total: 6 µs\n",
      "Wall time: 9.54 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def generateLogisticPipeline(inputCols, outputCol, threshold):\n",
    "    # Select input columns for linear regression\n",
    "    vecAssembler = VectorAssembler(inputCols=inputCols, outputCol=\"features\")\n",
    "\n",
    "    # Select output column for linear regression\n",
    "    logR = LogisticRegression(featuresCol=\"features\", labelCol=outputCol, rawPredictionCol = \"Logistic_Probabilities\", predictionCol = \"Logistic_Predictions\", threshold = threshold)\n",
    "\n",
    "    # The following lines (pipeline creation and fitting) replace these two commented-out lines.\n",
    "    # vecTrainDF = vecAssembler.transform(trainDF)\n",
    " \n",
    "    pipeline = Pipeline(stages=[vecAssembler, logR])\n",
    "    return pipeline\n",
    "    \n",
    "#pipeline = generateLogisticPipeline(inputCols, \"logistic_T_total_spend\")\n",
    "#pipelineModel = pipeline.fit(trainDF)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View the model information\n",
    "\n",
    "Create function to print out the model coefficients for the overall model, RMSE and R^2. We define the functions `modelInfo(inputCols, pipelineModel)` and `getEvaluationMetrics(pipelineModel,outputCol,testDF)` to report this information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelInfo(inputCols, pipelineModel):\n",
    "    # Create a zipped list containing the coefficients and the data\n",
    "    modelCols = copy.deepcopy(inputCols)\n",
    "    modelCoeffs = list(pipelineModel.stages[-1].coefficients)\n",
    "    modelCoeffs.insert(0,pipelineModel.stages[-1].intercept)\n",
    "    modelCols.insert(0,\"intercept\")\n",
    "    modelZippedList = list(map(list, zip(modelCols, modelCoeffs)))\n",
    "    \n",
    "    \n",
    "    # Create the pandas DataFrame\n",
    "    modelDF = pd.DataFrame(modelZippedList, columns = ['Column name', 'Coefficient'])\n",
    "    #modelDF['pValues'] = pvals\n",
    "    return modelDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate adjusted r2 (https://towardsdatascience.com/machine-learning-linear-regression-using-pyspark-9d5d5c772b42)\n",
    "# This function will allow us to calculate the adjusted r-square value when we do PCA later. The default r-square function does not take into account k. \n",
    "def adj_r2(r2, inputCols, testDF, k = 0):\n",
    "    n = testDF.count()\n",
    "    if k == 0:\n",
    "        p = len(inputCols)\n",
    "    else: \n",
    "        p = len(inputCols) + k - 1\n",
    "    \n",
    "    adjusted_r2 = 1-(((1-r2)*(n-1))/(n-p-1))\n",
    "    return adjusted_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://towardsdatascience.com/binary-classifier-evaluation-made-easy-with-handyspark-3b1e69c12b4f\n",
    "def getLogisticEvaluationMetrics(pipelineModel,outputCol,testDF,inputCols):\n",
    "    predDF = pipelineModel.transform(testDF)\n",
    "    preds_only = predDF.select(outputCol, \"Logistic_Predictions\")\n",
    "    preds_only.show(5)\n",
    "    \n",
    "    preds_only = preds_only.rdd\n",
    "    \n",
    "    metrics = MulticlassMetrics(preds_only)\n",
    "    print(metrics.confusionMatrix().toArray())\n",
    "    print(\"Accuracy: \" + str(metrics.accuracy))\n",
    "\n",
    "    return predDF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Column name  Coefficient\n",
      "0                      intercept    -1.087309\n",
      "1                    total_spend     0.000013\n",
      "2                   total_events     0.002369\n",
      "3                 total_sessions     0.147414\n",
      "4             avg_session_length    -0.000002\n",
      "5              sd_session_length     0.000003\n",
      "6   avg_interactions_per_session    -0.012783\n",
      "7    sd_interactions_per_session     0.004939\n",
      "8   max_interactions_per_session    -0.003006\n",
      "9   purchase_pct_of_total_events    -2.195029\n",
      "10      view_pct_of_total_events    -0.433863\n",
      "11      cart_pct_of_total_events    -0.796743\n",
      "12     avg_purchases_per_session    -0.272801\n",
      "13      sd_purchases_per_session     0.165081\n",
      "14                   cart_events    -0.005728\n",
      "15               purchase_events    -0.043132\n",
      "16        sessions_with_purchase     0.076717\n",
      "17            sessions_with_cart    -0.018144\n",
      "18            sessions_with_view    -0.162480\n",
      "19     pct_sessions_end_purchase     1.411522\n",
      "20         pct_sessions_end_cart     0.295980\n",
      "21               total_spend_log     0.026723\n",
      "22              total_events_log    -0.033250\n",
      "23           purchase_events_log     0.590121\n",
      "24            total_sessions_log     0.397916\n",
      "25        avg_session_length_log    -0.136904\n",
      "+----------------------+--------------------+\n",
      "|logistic_T_total_spend|Logistic_Predictions|\n",
      "+----------------------+--------------------+\n",
      "|                   0.0|                 0.0|\n",
      "|                   0.0|                 0.0|\n",
      "|                   0.0|                 0.0|\n",
      "|                   0.0|                 0.0|\n",
      "|                   0.0|                 1.0|\n",
      "+----------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "[[29122.  5872.]\n",
      " [24010. 12553.]]\n",
      "Accuracy: 0.5824028396942298\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "inputCols = [\"total_spend\", \"total_events\", \"total_sessions\", \"avg_session_length\", \"sd_session_length\", \"avg_interactions_per_session\", \n",
    "             \"sd_interactions_per_session\", \"max_interactions_per_session\", \"purchase_pct_of_total_events\", \"view_pct_of_total_events\",\n",
    "             \"cart_pct_of_total_events\", \"avg_purchases_per_session\", \"sd_purchases_per_session\", \"cart_events\", \"purchase_events\", \n",
    "             \"sessions_with_purchase\", \"sessions_with_cart\", \"sessions_with_view\", \"pct_sessions_end_purchase\", \n",
    "             \"pct_sessions_end_cart\", \"total_spend_log\", \"total_events_log\", \"purchase_events_log\", \"total_sessions_log\",\n",
    "             \"avg_session_length_log\"]\n",
    "outputCol= \"logistic_T_total_spend\"\n",
    "\n",
    "pipeline = generateLogisticPipeline(inputCols, outputCol, .2) #Iterative testing determined that a threshold of .2 led to the highest overal adj R^2 for the model\n",
    "pipelineModel = pipeline.fit(trainDF)\n",
    "\n",
    "print(modelInfo(inputCols, pipelineModel))\n",
    "\n",
    "logistic_predictions = getLogisticEvaluationMetrics(pipelineModel,outputCol,testDF, inputCols)\n",
    "#print(f\"RMSE is {evaluationMetrics[0]:.1f}\")\n",
    "#print(f\"R^2 is {evaluationMetrics[1]:.5f}\")\n",
    "#print(f\"Adjusted R^2 is {evaluationMetrics[2]:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Threshold of .2 maximizes model adj-r^2, though it does not maximize the accuracy of this logistic regression. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Next, we'll train a linear regression model using only the true positive training data, and generate a regression prediction for all test data that had a prediction of positive. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "part_2_train = trainDF.filter(col(\"logistic_T_total_spend\") == 1)\n",
    "part_2_test = logistic_predictions.filter(col(\"Logistic_Predictions\") == 1).withColumnRenamed('probability', \"ProbabilityLogistic\")\n",
    "\n",
    "part_1_test = logistic_predictions.filter(col(\"Logistic_Predictions\") == 0).withColumnRenamed('probability', \"ProbabilityLogistic\") \\\n",
    "    .withColumn(\"\", lit(None)) ## For overall accuracy metrics later, will be joined with output of part_2_test's regression predictions\n",
    "#part_1_test = part_1_test.withColumn(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74751\n",
      "36563\n"
     ]
    }
   ],
   "source": [
    "print(part_2_train.count())\n",
    "print(part_2_test.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14.2 ms, sys: 7.07 ms, total: 21.2 ms\n",
      "Wall time: 1.13 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def generateLinearPipeline(inputCols, outputCol):\n",
    "    # Select input columns for linear regression\n",
    "    vecAssembler = VectorAssembler(inputCols=inputCols, outputCol=\"features2\")\n",
    "\n",
    "    # Select output column for linear regression\n",
    "    lr = LinearRegression(featuresCol=\"features2\", labelCol=outputCol)\n",
    "\n",
    "    # The following lines (pipeline creation and fitting) replace these two commented-out lines.\n",
    "    # vecTrainDF = vecAssembler.transform(trainDF)\n",
    " \n",
    "    pipeline = Pipeline(stages=[vecAssembler, lr])\n",
    "    return pipeline\n",
    "    \n",
    "pipeline = generateLinearPipeline(inputCols, \"T_total_spend\")\n",
    "pipelineModel = pipeline.fit(trainDF)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLinearEvaluationMetrics(linearPipelineModel,outputCol,testDF,inputCols):\n",
    "    new_preds = pipelineModel.transform(testDF)\n",
    "    #new_preds.show(1)\n",
    "    #part_1_test.show(1)\n",
    "    \n",
    "    predDF = new_preds.unionByName(part_1_test, allowMissingColumns=True)\n",
    "    #predDF.show(1)\n",
    "\n",
    "    predDF = predDF.withColumn(\"FinalPredictions\", when(col(\"Logistic_Predictions\") == 0, 0.0)\n",
    "                               .otherwise(col(\"prediction\")))\n",
    "    #predDF.select(outputCol, \"prediction\").show(10)\n",
    "\n",
    "    predDF.select(outputCol, \"FinalPredictions\").show()\n",
    "    \n",
    "    regressionEvaluator = RegressionEvaluator(\n",
    "    predictionCol=\"FinalPredictions\",\n",
    "    labelCol=outputCol,\n",
    "    metricName=\"rmse\")\n",
    "    rmse = regressionEvaluator.evaluate(predDF)\n",
    "\n",
    "    regressionEvaluator = RegressionEvaluator(\n",
    "    predictionCol=\"FinalPredictions\",\n",
    "    labelCol=outputCol,\n",
    "    metricName=\"r2\")\n",
    "    r2 = regressionEvaluator.evaluate(predDF)\n",
    "      \n",
    "    # Manually calculate Adjusted r2\n",
    "    adjusted_r2 = adj_r2(r2, inputCols, predDF)\n",
    "    \n",
    "    return rmse, r2, adjusted_r2, predDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** All original inputs, original output **\n",
      "Model coefficients\n",
      "                     Column name  Coefficient\n",
      "0                      intercept   759.390544\n",
      "1                    total_spend     0.591320\n",
      "2                   total_events    -0.515724\n",
      "3                purchase_events    41.207359\n",
      "4                 total_sessions   -63.135401\n",
      "5             avg_session_length    -0.000520\n",
      "6   avg_interactions_per_session   -16.487473\n",
      "7   max_interactions_per_session     6.873946\n",
      "8   purchase_pct_of_total_events   443.417367\n",
      "9       view_pct_of_total_events  -103.816335\n",
      "10      cart_pct_of_total_events    26.430407\n",
      "11     avg_purchases_per_session  -337.477860\n",
      "12                   cart_events     5.579578\n",
      "13                   view_events    -1.099834\n",
      "14        sessions_with_purchase  -193.609708\n",
      "15            sessions_with_cart   148.251893\n",
      "16            sessions_with_view    60.564478\n",
      "17     pct_sessions_end_purchase   454.561538\n",
      "18         pct_sessions_end_cart  -854.405260\n",
      "19             sd_session_length     0.000365\n",
      "20   sd_interactions_per_session   -14.208624\n",
      "21      sd_purchases_per_session   314.403147\n",
      "+------------------+------------------+\n",
      "|     T_total_spend|  FinalPredictions|\n",
      "+------------------+------------------+\n",
      "|               0.0| 624.7580419820692|\n",
      "|               0.0| 526.3177997157919|\n",
      "| 312.4200134277344| 557.3234961943676|\n",
      "|  6009.78010559082| 1652.212288207612|\n",
      "|1627.1900024414062| 854.8646851048385|\n",
      "| 573.9199829101562| 782.6884607497873|\n",
      "| 622.4000244140625| 1788.701367191447|\n",
      "|               0.0|1296.7432441104554|\n",
      "|6970.7298583984375|1623.9171777948145|\n",
      "|               0.0| 948.4589205889183|\n",
      "|               0.0| 953.9965012378059|\n",
      "|5785.0001220703125|1821.4951009430863|\n",
      "|1130.3900146484375| 990.4017386337999|\n",
      "|102.16000366210938|1269.7101943918758|\n",
      "| 339.6800079345703| 5593.528169978718|\n",
      "|               0.0|1108.6551406431079|\n",
      "| 463.3199920654297| 926.9081231768264|\n",
      "|               0.0|1752.9039380219529|\n",
      "|              69.5| 986.9951445381696|\n",
      "| 2151.820037841797| 701.1800350565754|\n",
      "+------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "RMSE is 2301.5\n",
      "R^2 is 0.12762\n",
      "Adjusted R^2 is 0.12736\n"
     ]
    }
   ],
   "source": [
    "print(\"** All original inputs, original output **\")\n",
    "inputCols = [\"total_spend\",\"total_events\",\"purchase_events\", \"total_sessions\", \"avg_session_length\", \"avg_interactions_per_session\", \"max_interactions_per_session\",\n",
    "             \"purchase_pct_of_total_events\", \"view_pct_of_total_events\", \"cart_pct_of_total_events\",\"avg_purchases_per_session\", \"cart_events\", \"view_events\", \n",
    "             \"sessions_with_purchase\", \"sessions_with_cart\",\"sessions_with_view\", \"pct_sessions_end_purchase\", \"pct_sessions_end_cart\", 'sd_session_length', \n",
    "             'sd_interactions_per_session', 'sd_purchases_per_session']\n",
    "\n",
    "\n",
    "outputCol = \"T_total_spend\"\n",
    "\n",
    "pipeline = generateLinearPipeline(inputCols, outputCol)\n",
    "pipelineModel = pipeline.fit(part_2_train)\n",
    "\n",
    "print(\"Model coefficients\")\n",
    "print(modelInfo(inputCols, pipelineModel))\n",
    "\n",
    "evaluationMetrics = getLinearEvaluationMetrics(pipelineModel,outputCol,part_2_test, inputCols)\n",
    "print(f\"RMSE is {evaluationMetrics[0]:.1f}\")\n",
    "print(f\"R^2 is {evaluationMetrics[1]:.5f}\")\n",
    "print(f\"Adjusted R^2 is {evaluationMetrics[2]:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Champion Model **\n",
      "CPU times: user 5.29 s, sys: 1.78 s, total: 7.08 s\n",
      "Wall time: 28.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(\"** Champion Model **\")\n",
    "inputCols = [\"total_spend\",\"purchase_events\",\"avg_interactions_per_session\", \n",
    "             \"purchase_pct_of_total_events\",\"cart_events\", \"view_events\", \n",
    "             \"sessions_with_purchase\", \"sessions_with_cart\",\"pct_sessions_end_purchase\", \"pct_sessions_end_cart\",  \n",
    "             'sd_purchases_per_session']\n",
    "\n",
    "outputCol = \"T_total_spend\"\n",
    "# Below creation of pipeline is necessary for crossval to run. I wonder if there's a way to get it to run on the generate pipeline fn? \n",
    "vecAssembler = VectorAssembler(inputCols=inputCols, outputCol=\"features\")\n",
    "\n",
    "# Select output column for linear regression\n",
    "lr = LinearRegression(featuresCol=\"features\", labelCol=\"T_total_spend\")\n",
    "\n",
    "pipeline = Pipeline(stages=[vecAssembler, lr])\n",
    "    \n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(lr.regParam, [0, 0.01, 0.2, 1, 10]) \\\n",
    "    .addGrid(lr.elasticNetParam, [0, 0.25, 0.5, 0.75, 1]) \\\n",
    "    .build()\n",
    "\n",
    "crossval = CrossValidator(estimator=pipeline,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=RegressionEvaluator().setLabelCol(\"T_total_spend\"),\n",
    "                          numFolds=4)\n",
    "\n",
    "# Run cross-validation, and choose the best set of parameters.\n",
    "cvModel = crossval.setParallelism(8).fit(part_2_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model coefficients\n",
      "                     Column name  Coefficient\n",
      "0                      intercept   701.437134\n",
      "1                    total_spend     0.591951\n",
      "2                purchase_events     2.768463\n",
      "3   avg_interactions_per_session   -18.786724\n",
      "4   purchase_pct_of_total_events   513.610323\n",
      "5                    cart_events    14.224328\n",
      "6                    view_events    -0.595592\n",
      "7         sessions_with_purchase   -52.616400\n",
      "8             sessions_with_cart    52.633232\n",
      "9      pct_sessions_end_purchase    44.023084\n",
      "10         pct_sessions_end_cart  -216.749932\n",
      "11      sd_purchases_per_session   196.179439\n",
      "+------------------+------------------+\n",
      "|     T_total_spend|  FinalPredictions|\n",
      "+------------------+------------------+\n",
      "|               0.0| 624.7580419820692|\n",
      "|               0.0| 526.3177997157919|\n",
      "| 312.4200134277344| 557.3234961943676|\n",
      "|  6009.78010559082| 1652.212288207612|\n",
      "|1627.1900024414062| 854.8646851048385|\n",
      "| 573.9199829101562| 782.6884607497873|\n",
      "| 622.4000244140625| 1788.701367191447|\n",
      "|               0.0|1296.7432441104554|\n",
      "|6970.7298583984375|1623.9171777948145|\n",
      "|               0.0| 948.4589205889183|\n",
      "|               0.0| 953.9965012378059|\n",
      "|5785.0001220703125|1821.4951009430863|\n",
      "|1130.3900146484375| 990.4017386337999|\n",
      "|102.16000366210938|1269.7101943918758|\n",
      "| 339.6800079345703| 5593.528169978718|\n",
      "|               0.0|1108.6551406431079|\n",
      "| 463.3199920654297| 926.9081231768264|\n",
      "|               0.0|1752.9039380219529|\n",
      "|              69.5| 986.9951445381696|\n",
      "| 2151.820037841797| 701.1800350565754|\n",
      "+------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "RMSE is 2301.5\n",
      "R^2 is 0.12762\n",
      "Adjusted R^2 is 0.12749\n",
      "\n",
      "{Param(parent='LinearRegression_dd8724e9af5f', name='regParam', doc='regularization parameter (>= 0).'): 0.2, Param(parent='LinearRegression_dd8724e9af5f', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.75}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best model coefficients\")\n",
    "print(modelInfo(inputCols, cvModel.bestModel))\n",
    "\n",
    "\n",
    "evaluationMetrics = getLinearEvaluationMetrics(cvModel.bestModel,\"T_total_spend\",part_2_test,inputCols)\n",
    "print(f\"RMSE is {evaluationMetrics[0]:.1f}\")\n",
    "print(f\"R^2 is {evaluationMetrics[1]:.5f}\")\n",
    "print(f\"Adjusted R^2 is {evaluationMetrics[2]:.5f}\")\n",
    "\n",
    "print()\n",
    "print(cvModel.getEstimatorParamMaps()[np.argmax(cvModel.avgMetrics)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DS 5110 Spark 3.1",
   "language": "python",
   "name": "ds5110_spark3.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
